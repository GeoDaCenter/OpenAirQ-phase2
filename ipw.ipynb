{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/opt/anaconda3/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import KMeans\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "      <th>week</th>\n",
       "      <th>aod</th>\n",
       "      <th>elev</th>\n",
       "      <th>temp</th>\n",
       "      <th>mslp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wk_1_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wk_2_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Wk_3_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Wk_4_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Wk_5_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575995</th>\n",
       "      <td>59000</td>\n",
       "      <td>Wk_49_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575996</th>\n",
       "      <td>59000</td>\n",
       "      <td>Wk_50_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575997</th>\n",
       "      <td>59000</td>\n",
       "      <td>Wk_51_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575998</th>\n",
       "      <td>59000</td>\n",
       "      <td>Wk_52_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15575999</th>\n",
       "      <td>59000</td>\n",
       "      <td>Wk_53_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15576000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cell        week  aod  elev  temp  mslp\n",
       "0             1   Wk_1_2014  NaN   NaN   NaN   NaN\n",
       "1             1   Wk_2_2014  NaN   NaN   NaN   NaN\n",
       "2             1   Wk_3_2014  NaN   NaN   NaN   NaN\n",
       "3             1   Wk_4_2014  NaN   NaN   NaN   NaN\n",
       "4             1   Wk_5_2014  NaN   NaN   NaN   NaN\n",
       "...         ...         ...  ...   ...   ...   ...\n",
       "15575995  59000  Wk_49_2018  NaN   NaN   NaN   NaN\n",
       "15575996  59000  Wk_50_2018  NaN   NaN   NaN   NaN\n",
       "15575997  59000  Wk_51_2018  NaN   NaN   NaN   NaN\n",
       "15575998  59000  Wk_52_2018  NaN   NaN   NaN   NaN\n",
       "15575999  59000  Wk_53_2018  NaN   NaN   NaN   NaN\n",
       "\n",
       "[15576000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../../Downloads/AOD_series_IPW.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cull = pd.DataFrame(data[~np.isnan(data[\"temp\"])], copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "      <th>week</th>\n",
       "      <th>aod</th>\n",
       "      <th>elev</th>\n",
       "      <th>temp</th>\n",
       "      <th>mslp</th>\n",
       "      <th>exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111408</th>\n",
       "      <td>423</td>\n",
       "      <td>Wk_1_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.192496</td>\n",
       "      <td>10.066939</td>\n",
       "      <td>1022.410950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111409</th>\n",
       "      <td>423</td>\n",
       "      <td>Wk_2_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.192496</td>\n",
       "      <td>10.081455</td>\n",
       "      <td>1018.204102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111410</th>\n",
       "      <td>423</td>\n",
       "      <td>Wk_3_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.192496</td>\n",
       "      <td>21.171682</td>\n",
       "      <td>1007.017456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111411</th>\n",
       "      <td>423</td>\n",
       "      <td>Wk_4_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.192496</td>\n",
       "      <td>8.754344</td>\n",
       "      <td>1015.050781</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111412</th>\n",
       "      <td>423</td>\n",
       "      <td>Wk_5_2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.192496</td>\n",
       "      <td>8.272011</td>\n",
       "      <td>1019.083618</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561475</th>\n",
       "      <td>58945</td>\n",
       "      <td>Wk_49_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.712208</td>\n",
       "      <td>33.953037</td>\n",
       "      <td>1010.413391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561476</th>\n",
       "      <td>58945</td>\n",
       "      <td>Wk_50_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.712208</td>\n",
       "      <td>27.300304</td>\n",
       "      <td>1025.005981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561477</th>\n",
       "      <td>58945</td>\n",
       "      <td>Wk_51_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.712208</td>\n",
       "      <td>34.047974</td>\n",
       "      <td>1019.825012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561478</th>\n",
       "      <td>58945</td>\n",
       "      <td>Wk_52_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.712208</td>\n",
       "      <td>35.349667</td>\n",
       "      <td>1014.067566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15561479</th>\n",
       "      <td>58945</td>\n",
       "      <td>Wk_53_2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.712208</td>\n",
       "      <td>34.197220</td>\n",
       "      <td>1021.775818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8092656 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           cell        week  aod        elev       temp         mslp  exists\n",
       "111408      423   Wk_1_2014  NaN  265.192496  10.066939  1022.410950       0\n",
       "111409      423   Wk_2_2014  NaN  265.192496  10.081455  1018.204102       0\n",
       "111410      423   Wk_3_2014  NaN  265.192496  21.171682  1007.017456       0\n",
       "111411      423   Wk_4_2014  NaN  265.192496   8.754344  1015.050781       0\n",
       "111412      423   Wk_5_2014  NaN  265.192496   8.272011  1019.083618       0\n",
       "...         ...         ...  ...         ...        ...          ...     ...\n",
       "15561475  58945  Wk_49_2018  NaN  223.712208  33.953037  1010.413391       0\n",
       "15561476  58945  Wk_50_2018  NaN  223.712208  27.300304  1025.005981       0\n",
       "15561477  58945  Wk_51_2018  NaN  223.712208  34.047974  1019.825012       0\n",
       "15561478  58945  Wk_52_2018  NaN  223.712208  35.349667  1014.067566       0\n",
       "15561479  58945  Wk_53_2018  NaN  223.712208  34.197220  1021.775818       0\n",
       "\n",
       "[8092656 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cull[\"exists\"] = -np.isnan(data_cull[\"aod\"]).astype(int) + 1\n",
    "data_cull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_cull[[\"elev\", \"temp\", \"mslp\"]]\n",
    "y = data_cull[\"exists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipw_model = LogisticRegression(random_state = 1312).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3829273097032682"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y, ipw_model.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipw_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.32604128, 5.29728399, 3.4146381 , ..., 2.18013573, 2.09603664,\n",
       "       2.17449365])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipw = 1 / ipw_model.predict_proba(X)[:, 1]\n",
    "ipw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, adding a model that considers week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "week = np.char.partition(np.char.partition(np.array(data_cull[\"week\"], str), sep=\"_\")[:, 2], sep=\"_\")[:, 0]\n",
    "year = np.char.partition(np.char.partition(np.array(data_cull[\"week\"], str), sep=\"_\")[:, 2], sep=\"_\")[:, 2]\n",
    "year = year.astype(int) - 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([data_cull[[\"elev\", \"temp\", \"mslp\"]].reset_index(drop=True), pd.Series(week)], axis=1)\n",
    "y = data_cull[\"exists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.index = data_cull.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipw_model = LogisticRegression(random_state = 1312).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38244091297258237"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y, ipw_model.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are slightly better; as this model is in line with the literature we'll keep it regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipw_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.04411525, 5.03525883, 3.24770256, ..., 2.32838869, 2.23740766,\n",
       "       2.33302117])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipw = 1 / ipw_model.predict_proba(X)[:, 1]\n",
    "ipw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we need this model to be monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>cell</th>\n",
       "      <th>aod</th>\n",
       "      <th>elev</th>\n",
       "      <th>temp</th>\n",
       "      <th>mslp</th>\n",
       "      <th>exists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.192496</td>\n",
       "      <td>12.518605</td>\n",
       "      <td>1015.670822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.061731</td>\n",
       "      <td>12.529349</td>\n",
       "      <td>1015.670273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267.379445</td>\n",
       "      <td>12.539673</td>\n",
       "      <td>1015.669708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267.551459</td>\n",
       "      <td>12.549627</td>\n",
       "      <td>1015.669189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.196258</td>\n",
       "      <td>12.559257</td>\n",
       "      <td>1015.668625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992505</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>58941</td>\n",
       "      <td>0.180513</td>\n",
       "      <td>227.276341</td>\n",
       "      <td>54.864787</td>\n",
       "      <td>1018.436792</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992506</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>58942</td>\n",
       "      <td>0.214781</td>\n",
       "      <td>227.543436</td>\n",
       "      <td>54.865610</td>\n",
       "      <td>1018.436548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992507</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>58943</td>\n",
       "      <td>0.142192</td>\n",
       "      <td>226.309607</td>\n",
       "      <td>54.866460</td>\n",
       "      <td>1018.436328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992508</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>58944</td>\n",
       "      <td>0.151084</td>\n",
       "      <td>224.323911</td>\n",
       "      <td>54.867332</td>\n",
       "      <td>1018.436084</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992509</th>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>58945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.712208</td>\n",
       "      <td>54.866257</td>\n",
       "      <td>1018.435742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1992510 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year   cell       aod        elev       temp         mslp  \\\n",
       "0           0    14    423       NaN  265.192496  12.518605  1015.670822   \n",
       "1           0    14    424       NaN  268.061731  12.529349  1015.670273   \n",
       "2           0    14    425       NaN  267.379445  12.539673  1015.669708   \n",
       "3           0    14    426       NaN  267.551459  12.549627  1015.669189   \n",
       "4           0    14    427       NaN  273.196258  12.559257  1015.668625   \n",
       "...       ...   ...    ...       ...         ...        ...          ...   \n",
       "1992505     9    18  58941  0.180513  227.276341  54.864787  1018.436792   \n",
       "1992506     9    18  58942  0.214781  227.543436  54.865610  1018.436548   \n",
       "1992507     9    18  58943  0.142192  226.309607  54.866460  1018.436328   \n",
       "1992508     9    18  58944  0.151084  224.323911  54.867332  1018.436084   \n",
       "1992509     9    18  58945       NaN  223.712208  54.866257  1018.435742   \n",
       "\n",
       "         exists  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "...         ...  \n",
       "1992505       1  \n",
       "1992506       1  \n",
       "1992507       1  \n",
       "1992508       1  \n",
       "1992509       0  \n",
       "\n",
       "[1992510 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cull[\"month\"] = (week.astype(int) / (53 / 12)).astype(int).astype(str)\n",
    "data_cull[\"year\"] = year\n",
    "data_month = data_cull.groupby([\"month\", \"year\", \"cell\"]).mean().reset_index()\n",
    "data_month[\"exists\"] = -np.isnan(data_month[\"aod\"]).astype(int) + 1\n",
    "data_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_month[[\"elev\", \"temp\", \"mslp\", \"month\"]]\n",
    "y = data_month[\"exists\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipw_model = LogisticRegression(random_state = 1312).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18401509148112435"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y, ipw_model.predict_proba(X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll pull in data for the old neural net, and create IPW weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raster.Cell</th>\n",
       "      <th>Sen2.5</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>AOD</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Elev</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Vsby</th>\n",
       "      <th>WdVl</th>\n",
       "      <th>...</th>\n",
       "      <th>LC_LowDev</th>\n",
       "      <th>LC_HighDev</th>\n",
       "      <th>PS</th>\n",
       "      <th>relh</th>\n",
       "      <th>Popd</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3798</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.102649</td>\n",
       "      <td>27.214394</td>\n",
       "      <td>202.651108</td>\n",
       "      <td>1018.851624</td>\n",
       "      <td>8.472521</td>\n",
       "      <td>8.406699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.406699</td>\n",
       "      <td>13.146420</td>\n",
       "      <td>68.591485</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-87.914368</td>\n",
       "      <td>43.056945</td>\n",
       "      <td>83.388515</td>\n",
       "      <td>8613.328516</td>\n",
       "      <td>1269.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3798</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.062412</td>\n",
       "      <td>42.552032</td>\n",
       "      <td>202.651108</td>\n",
       "      <td>1014.221252</td>\n",
       "      <td>8.791099</td>\n",
       "      <td>8.715958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>8.715958</td>\n",
       "      <td>13.146420</td>\n",
       "      <td>67.143758</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-87.914368</td>\n",
       "      <td>43.056945</td>\n",
       "      <td>83.388515</td>\n",
       "      <td>8613.328516</td>\n",
       "      <td>1269.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3798</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.181493</td>\n",
       "      <td>55.138329</td>\n",
       "      <td>202.651108</td>\n",
       "      <td>1015.420776</td>\n",
       "      <td>9.179679</td>\n",
       "      <td>7.012032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>7.012032</td>\n",
       "      <td>13.146420</td>\n",
       "      <td>68.574740</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-87.914368</td>\n",
       "      <td>43.056945</td>\n",
       "      <td>83.388515</td>\n",
       "      <td>8613.328516</td>\n",
       "      <td>1269.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3798</td>\n",
       "      <td>7.571429</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.165752</td>\n",
       "      <td>63.757431</td>\n",
       "      <td>202.651108</td>\n",
       "      <td>1013.547974</td>\n",
       "      <td>7.342515</td>\n",
       "      <td>6.381063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>6.381063</td>\n",
       "      <td>13.146420</td>\n",
       "      <td>74.554604</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-87.914368</td>\n",
       "      <td>43.056945</td>\n",
       "      <td>83.388515</td>\n",
       "      <td>8613.328516</td>\n",
       "      <td>1269.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3798</td>\n",
       "      <td>8.471429</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.299681</td>\n",
       "      <td>66.077019</td>\n",
       "      <td>202.651108</td>\n",
       "      <td>1015.308838</td>\n",
       "      <td>9.463487</td>\n",
       "      <td>6.096744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247</td>\n",
       "      <td>6.096744</td>\n",
       "      <td>13.146420</td>\n",
       "      <td>69.644172</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>-87.914368</td>\n",
       "      <td>43.056945</td>\n",
       "      <td>83.388515</td>\n",
       "      <td>8613.328516</td>\n",
       "      <td>1269.449331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>46895</td>\n",
       "      <td>6.649239</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>0.150367</td>\n",
       "      <td>71.891273</td>\n",
       "      <td>180.495621</td>\n",
       "      <td>1012.823486</td>\n",
       "      <td>8.968293</td>\n",
       "      <td>5.528109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.528109</td>\n",
       "      <td>9.735624</td>\n",
       "      <td>77.871421</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-88.185768</td>\n",
       "      <td>41.224345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>46895</td>\n",
       "      <td>7.206279</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>0.203455</td>\n",
       "      <td>73.688965</td>\n",
       "      <td>180.495621</td>\n",
       "      <td>1017.014465</td>\n",
       "      <td>9.619825</td>\n",
       "      <td>4.504867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.504867</td>\n",
       "      <td>9.735624</td>\n",
       "      <td>74.239351</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-88.185768</td>\n",
       "      <td>41.224345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>46895</td>\n",
       "      <td>9.570144</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>0.287290</td>\n",
       "      <td>73.940506</td>\n",
       "      <td>180.495621</td>\n",
       "      <td>1015.084167</td>\n",
       "      <td>9.030977</td>\n",
       "      <td>4.548747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.548747</td>\n",
       "      <td>9.735624</td>\n",
       "      <td>77.673073</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-88.185768</td>\n",
       "      <td>41.224345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>46895</td>\n",
       "      <td>5.248297</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>0.102493</td>\n",
       "      <td>52.086712</td>\n",
       "      <td>180.495621</td>\n",
       "      <td>1017.470093</td>\n",
       "      <td>9.208525</td>\n",
       "      <td>6.414171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.414171</td>\n",
       "      <td>9.735624</td>\n",
       "      <td>75.775710</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-88.185768</td>\n",
       "      <td>41.224345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>46895</td>\n",
       "      <td>8.117671</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>0.141831</td>\n",
       "      <td>32.807404</td>\n",
       "      <td>180.495621</td>\n",
       "      <td>1018.717285</td>\n",
       "      <td>8.256618</td>\n",
       "      <td>6.406942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6.406942</td>\n",
       "      <td>9.735624</td>\n",
       "      <td>83.352918</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>-88.185768</td>\n",
       "      <td>41.224345</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1495 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Raster.Cell     Sen2.5  month  year       AOD       Temp        Elev  \\\n",
       "0            3798  14.300000      3    14  0.102649  27.214394  202.651108   \n",
       "1            3798   6.800000      4    14  0.062412  42.552032  202.651108   \n",
       "2            3798   5.600000      5    14  0.181493  55.138329  202.651108   \n",
       "3            3798   7.571429      6    14  0.165752  63.757431  202.651108   \n",
       "4            3798   8.471429      7    14  0.299681  66.077019  202.651108   \n",
       "...           ...        ...    ...   ...       ...        ...         ...   \n",
       "1490        46895   6.649239      6    18  0.150367  71.891273  180.495621   \n",
       "1491        46895   7.206279      7    18  0.203455  73.688965  180.495621   \n",
       "1492        46895   9.570144      8    18  0.287290  73.940506  180.495621   \n",
       "1493        46895   5.248297     10    18  0.102493  52.086712  180.495621   \n",
       "1494        46895   8.117671     12    18  0.141831  32.807404  180.495621   \n",
       "\n",
       "             MSLP      Vsby      WdVl  ...  LC_LowDev  LC_HighDev         PS  \\\n",
       "0     1018.851624  8.472521  8.406699  ...      0.247    8.406699  13.146420   \n",
       "1     1014.221252  8.791099  8.715958  ...      0.247    8.715958  13.146420   \n",
       "2     1015.420776  9.179679  7.012032  ...      0.247    7.012032  13.146420   \n",
       "3     1013.547974  7.342515  6.381063  ...      0.247    6.381063  13.146420   \n",
       "4     1015.308838  9.463487  6.096744  ...      0.247    6.096744  13.146420   \n",
       "...           ...       ...       ...  ...        ...         ...        ...   \n",
       "1490  1012.823486  8.968293  5.528109  ...      0.000    5.528109   9.735624   \n",
       "1491  1017.014465  9.619825  4.504867  ...      0.000    4.504867   9.735624   \n",
       "1492  1015.084167  9.030977  4.548747  ...      0.000    4.548747   9.735624   \n",
       "1493  1017.470093  9.208525  6.414171  ...      0.000    6.414171   9.735624   \n",
       "1494  1018.717285  8.256618  6.406942  ...      0.000    6.406942   9.735624   \n",
       "\n",
       "           relh      Popd          x          y    primary    secondary  \\\n",
       "0     68.591485  0.002802 -87.914368  43.056945  83.388515  8613.328516   \n",
       "1     67.143758  0.002802 -87.914368  43.056945  83.388515  8613.328516   \n",
       "2     68.574740  0.002802 -87.914368  43.056945  83.388515  8613.328516   \n",
       "3     74.554604  0.002802 -87.914368  43.056945  83.388515  8613.328516   \n",
       "4     69.644172  0.002802 -87.914368  43.056945  83.388515  8613.328516   \n",
       "...         ...       ...        ...        ...        ...          ...   \n",
       "1490  77.871421  0.000037 -88.185768  41.224345   0.000000     0.000000   \n",
       "1491  74.239351  0.000037 -88.185768  41.224345   0.000000     0.000000   \n",
       "1492  77.673073  0.000037 -88.185768  41.224345   0.000000     0.000000   \n",
       "1493  75.775710  0.000037 -88.185768  41.224345   0.000000     0.000000   \n",
       "1494  83.352918  0.000037 -88.185768  41.224345   0.000000     0.000000   \n",
       "\n",
       "         motorway  \n",
       "0     1269.449331  \n",
       "1     1269.449331  \n",
       "2     1269.449331  \n",
       "3     1269.449331  \n",
       "4     1269.449331  \n",
       "...           ...  \n",
       "1490     0.000000  \n",
       "1491     0.000000  \n",
       "1492     0.000000  \n",
       "1493     0.000000  \n",
       "1494     0.000000  \n",
       "\n",
       "[1495 rows x 22 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../Downloads/first_stage_20210601.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the outliers\n",
    "df=df[df['Sen2.5']<20].reset_index()\n",
    "df = df.drop([\"index\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.50436348, 1.06891261, 1.01377333, ..., 1.00125491, 1.02824869,\n",
       "       1.44869803])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipw_weights = 1 / ipw_model.predict_proba(df[[\"Elev\", \"Temp\", \"MSLP\", \"month\"]])[:, 1]\n",
    "ipw_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, replicate the scikit-learn MLPRegressor framework in keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data as in original nn\n",
    "df2 = df.join(pd.get_dummies(df['month'],drop_first=True)).join(pd.get_dummies(df['year'],drop_first=True))\n",
    "df2 = df2.drop([\"month\",\"year\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopper = EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = Sequential()\n",
    "mlp.add(Dense(10, activation=\"relu\"))\n",
    "mlp.add(Dense(10, activation=\"relu\"))\n",
    "mlp.add(Dense(1))\n",
    "# note: batches default to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "8/8 [==============================] - 0s 932us/step - loss: 343772.7188\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 228603.4375\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 154059.8281\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 103130.3359\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 68746.7969\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 909us/step - loss: 47792.1914\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 34673.0781\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 820us/step - loss: 25025.1953\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 18770.8340\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14444.6338\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 973us/step - loss: 11415.7939\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 9248.6396\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 7630.6660\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 6354.6528\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5314.5210\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4442.6621\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3693.9883\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3069.0789\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2543.6414\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 903us/step - loss: 1991.5598\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1549.2803\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 948us/step - loss: 1234.4390\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1082.4264\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 938.6514\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 816.7910\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 720.4440\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 639.4725\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 972us/step - loss: 570.5464\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 842us/step - loss: 512.5427\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 998us/step - loss: 464.0334\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 423.1842\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 389.9289\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 855us/step - loss: 363.2457\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 867us/step - loss: 341.0606\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 322.9416\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 307.5072\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 295.8554\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 977us/step - loss: 284.5137\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 274.4852\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 266.5391\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 870us/step - loss: 259.0046\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 252.7141\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 883us/step - loss: 246.7115\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 241.3344\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 831us/step - loss: 236.0917\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 231.2118\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 226.6719\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 222.3129\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 218.2068\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 214.0727\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 210.2331\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 776us/step - loss: 206.7009\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 203.1035\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 199.7620\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 783us/step - loss: 196.5281\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 193.1368\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 190.0999\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 804us/step - loss: 186.8708\n",
      "Epoch 59/2000\n",
      "8/8 [==============================] - 0s 919us/step - loss: 183.6986\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 180.7302\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 864us/step - loss: 177.7537\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 943us/step - loss: 174.9295\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 172.0410\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 864us/step - loss: 169.1998\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 166.3386\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 163.4447\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 957us/step - loss: 160.4638\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 987us/step - loss: 157.2798\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 898us/step - loss: 154.0778\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 945us/step - loss: 151.0263\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 148.0398\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 805us/step - loss: 145.3052\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 941us/step - loss: 142.7165\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 140.2544\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 137.8674\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 802us/step - loss: 135.6542\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 988us/step - loss: 133.4945\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 785us/step - loss: 131.3810\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 823us/step - loss: 129.3622\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 127.3263\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 896us/step - loss: 125.4645\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 123.4834\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 121.6367\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 909us/step - loss: 119.8021\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 118.1124\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 116.3664\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 985us/step - loss: 114.7756\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 770us/step - loss: 113.1911\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 992us/step - loss: 111.6239\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 110.0995\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 108.6246\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 783us/step - loss: 107.2108\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 105.7574\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 104.3441\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 781us/step - loss: 103.0370\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 816us/step - loss: 101.7260\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 852us/step - loss: 100.4705\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 99.2303\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 98.0702\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 96.8365\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 810us/step - loss: 95.6648\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 805us/step - loss: 94.5680\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 93.4588\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 980us/step - loss: 92.4296\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 990us/step - loss: 91.3211\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 767us/step - loss: 90.3371\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 799us/step - loss: 89.3317\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 88.3938\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 87.4482\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 858us/step - loss: 86.5142\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 930us/step - loss: 85.6378\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 84.7570\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 750us/step - loss: 83.9018\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 83.0678\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 861us/step - loss: 82.2309\n",
      "Epoch 116/2000\n",
      "8/8 [==============================] - 0s 918us/step - loss: 81.4271\n",
      "Epoch 117/2000\n",
      "8/8 [==============================] - 0s 993us/step - loss: 80.6494\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 764us/step - loss: 79.8716\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 967us/step - loss: 79.1328\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 971us/step - loss: 78.3971\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 77.6929\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 878us/step - loss: 76.9752\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 849us/step - loss: 76.2477\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 887us/step - loss: 75.5786\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 74.9165\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 74.2577\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 763us/step - loss: 73.6568\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 930us/step - loss: 73.0329\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 869us/step - loss: 72.4378\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 71.8361\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 778us/step - loss: 71.2447\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 792us/step - loss: 70.7073\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 977us/step - loss: 70.1640\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 776us/step - loss: 69.6259\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 724us/step - loss: 69.0386\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 813us/step - loss: 68.5250\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 892us/step - loss: 67.9848\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 880us/step - loss: 67.4833\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 889us/step - loss: 66.9896\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 736us/step - loss: 66.5060\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 751us/step - loss: 66.0175\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 65.5366\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 842us/step - loss: 65.1174\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 948us/step - loss: 64.5713\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 848us/step - loss: 64.1287\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 769us/step - loss: 63.6828\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 820us/step - loss: 63.2384\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 772us/step - loss: 62.7866\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 828us/step - loss: 62.3403\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 767us/step - loss: 61.9072\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 949us/step - loss: 61.4935\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 962us/step - loss: 61.0818\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 755us/step - loss: 60.6408\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 769us/step - loss: 60.2432\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 781us/step - loss: 59.8643\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 892us/step - loss: 59.4621\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 703us/step - loss: 59.0643\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 893us/step - loss: 58.7019\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 58.2904\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 981us/step - loss: 57.9229\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 755us/step - loss: 57.5814\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 829us/step - loss: 57.1804\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 760us/step - loss: 56.8100\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 709us/step - loss: 56.4582\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 779us/step - loss: 56.1037\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 55.7618\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 867us/step - loss: 55.3978\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 761us/step - loss: 55.0488\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 785us/step - loss: 54.7234\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 801us/step - loss: 54.3680\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 995us/step - loss: 54.0450\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 720us/step - loss: 53.7059\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 760us/step - loss: 53.3729\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 863us/step - loss: 53.0387\n",
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 904us/step - loss: 52.7313\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 815us/step - loss: 52.4009\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 816us/step - loss: 52.1302\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 924us/step - loss: 51.7778\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 737us/step - loss: 51.4788\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 51.1731\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 979us/step - loss: 50.8208\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 50.5239\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 743us/step - loss: 50.2261\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 965us/step - loss: 49.9076\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 784us/step - loss: 49.6171\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 846us/step - loss: 49.3071\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 49.0017\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 48.7184\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 791us/step - loss: 48.4349\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 48.1291\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 688us/step - loss: 47.8896\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 47.5694\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 906us/step - loss: 47.2908\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 828us/step - loss: 46.9835\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 713us/step - loss: 46.6827\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 675us/step - loss: 46.4090\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 894us/step - loss: 46.1124\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 728us/step - loss: 45.8289\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 813us/step - loss: 45.5780\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 786us/step - loss: 45.2956\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 750us/step - loss: 45.0529\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 744us/step - loss: 44.7332\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 869us/step - loss: 44.4891\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 44.2127\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 43.9401\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 759us/step - loss: 43.6848\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 809us/step - loss: 43.4151\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 739us/step - loss: 43.1703\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 710us/step - loss: 42.8897\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 698us/step - loss: 42.6345\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 781us/step - loss: 42.4040\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 42.1390\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 685us/step - loss: 41.8594\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 41.6256\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 841us/step - loss: 41.3732\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 747us/step - loss: 41.1229\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 720us/step - loss: 40.8787\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 750us/step - loss: 40.6562\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 778us/step - loss: 40.4027\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 40.1428\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 672us/step - loss: 39.9272\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 705us/step - loss: 39.6865\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 709us/step - loss: 39.4539\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 699us/step - loss: 39.2441\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 706us/step - loss: 38.9677\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 795us/step - loss: 38.7623\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 881us/step - loss: 38.5001\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 38.2586\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 800us/step - loss: 38.0367\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 779us/step - loss: 37.8263\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 37.6223\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 37.4085\n",
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 728us/step - loss: 37.1497\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 752us/step - loss: 36.9311\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 36.7144\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 867us/step - loss: 36.4783\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 36.2760\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 36.0903\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 942us/step - loss: 35.8616\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 699us/step - loss: 35.6287\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 699us/step - loss: 35.4474\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 814us/step - loss: 35.2026\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 902us/step - loss: 35.0034\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 735us/step - loss: 34.8232\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 34.6088\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 899us/step - loss: 34.4317\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 34.1887\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 692us/step - loss: 33.9948\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 33.7933\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 860us/step - loss: 33.5985\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 714us/step - loss: 33.4105\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 976us/step - loss: 33.2070\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 709us/step - loss: 33.0142\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 698us/step - loss: 32.8297\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 676us/step - loss: 32.6369\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 767us/step - loss: 32.4367\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 769us/step - loss: 32.2757\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 962us/step - loss: 32.0884\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 31.8719\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 700us/step - loss: 31.7259\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 678us/step - loss: 31.5356\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 900us/step - loss: 31.3335\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 713us/step - loss: 31.1579\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 831us/step - loss: 30.9882\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 719us/step - loss: 30.8087\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 956us/step - loss: 30.6660\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 781us/step - loss: 30.4171\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 30.2672\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 30.0787\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 29.9101\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 668us/step - loss: 29.7562\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 29.5639\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 657us/step - loss: 29.3942\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 863us/step - loss: 29.2203\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 726us/step - loss: 29.0646\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 798us/step - loss: 28.8725\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 716us/step - loss: 28.7226\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 775us/step - loss: 28.5417\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 730us/step - loss: 28.4015\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 719us/step - loss: 28.2247\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 960us/step - loss: 28.1140\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 27.9282\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 27.7745\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 706us/step - loss: 27.5775\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 620us/step - loss: 27.4586\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 600us/step - loss: 27.2915\n",
      "Epoch 287/2000\n",
      "8/8 [==============================] - 0s 758us/step - loss: 27.1170\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 744us/step - loss: 26.9938\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 912us/step - loss: 26.8406\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 26.7118\n",
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 708us/step - loss: 26.5451\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 731us/step - loss: 26.4324\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 769us/step - loss: 26.2861\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 26.1509\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 784us/step - loss: 25.9687\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 25.8574\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 25.6984\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 25.5673\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 607us/step - loss: 25.4143\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 706us/step - loss: 25.2954\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 25.1587\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 665us/step - loss: 25.0263\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 24.8886\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 811us/step - loss: 24.7690\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 833us/step - loss: 24.6413\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 24.5353\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 700us/step - loss: 24.4178\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 854us/step - loss: 24.2678\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 741us/step - loss: 24.1497\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 676us/step - loss: 24.0303\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 687us/step - loss: 23.8991\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 660us/step - loss: 23.7889\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 587us/step - loss: 23.6743\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 618us/step - loss: 23.5316\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 765us/step - loss: 23.4514\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 774us/step - loss: 23.3334\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 994us/step - loss: 23.2114\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 710us/step - loss: 23.0925\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 22.9716\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 670us/step - loss: 22.8972\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 592us/step - loss: 22.7632\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 22.6675\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 824us/step - loss: 22.5601\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 685us/step - loss: 22.4444\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 722us/step - loss: 22.3620\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 856us/step - loss: 22.2551\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 841us/step - loss: 22.1543\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 22.0365\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 692us/step - loss: 21.9310\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 666us/step - loss: 21.8439\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 591us/step - loss: 21.7325\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 902us/step - loss: 21.6610\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 21.5431\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 21.4419\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 947us/step - loss: 21.3458\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 690us/step - loss: 21.2588\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 671us/step - loss: 21.1546\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 664us/step - loss: 21.0781\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 597us/step - loss: 21.0171\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 594us/step - loss: 20.9062\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 841us/step - loss: 20.8087\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 931us/step - loss: 20.7195\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 20.6267\n",
      "Epoch 344/2000\n",
      "8/8 [==============================] - 0s 689us/step - loss: 20.5730\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 667us/step - loss: 20.4593\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 644us/step - loss: 20.3955\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 579us/step - loss: 20.3202\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 573us/step - loss: 20.2214\n",
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 801us/step - loss: 20.1320\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 656us/step - loss: 20.0366\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 854us/step - loss: 19.9774\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 667us/step - loss: 19.9016\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 668us/step - loss: 19.7919\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 895us/step - loss: 19.7533\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 797us/step - loss: 19.6357\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 746us/step - loss: 19.5806\n",
      "Epoch 357/2000\n",
      "8/8 [==============================] - 0s 696us/step - loss: 19.5021\n",
      "Epoch 358/2000\n",
      "8/8 [==============================] - 0s 685us/step - loss: 19.4043\n",
      "Epoch 359/2000\n",
      "8/8 [==============================] - 0s 689us/step - loss: 19.3461\n",
      "Epoch 360/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 19.2741\n",
      "Epoch 361/2000\n",
      "8/8 [==============================] - 0s 588us/step - loss: 19.2223\n",
      "Epoch 362/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 19.1287\n",
      "Epoch 363/2000\n",
      "8/8 [==============================] - 0s 584us/step - loss: 19.0705\n",
      "Epoch 364/2000\n",
      "8/8 [==============================] - 0s 600us/step - loss: 19.0044\n",
      "Epoch 365/2000\n",
      "8/8 [==============================] - 0s 782us/step - loss: 18.9472\n",
      "Epoch 366/2000\n",
      "8/8 [==============================] - 0s 631us/step - loss: 18.8984\n",
      "Epoch 367/2000\n",
      "8/8 [==============================] - 0s 831us/step - loss: 18.8415\n",
      "Epoch 368/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 18.7699\n",
      "Epoch 369/2000\n",
      "8/8 [==============================] - 0s 643us/step - loss: 18.7482\n",
      "Epoch 370/2000\n",
      "8/8 [==============================] - 0s 764us/step - loss: 18.6862\n",
      "Epoch 371/2000\n",
      "8/8 [==============================] - 0s 829us/step - loss: 18.5846\n",
      "Epoch 372/2000\n",
      "8/8 [==============================] - 0s 676us/step - loss: 18.5461\n",
      "Epoch 373/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 18.5072\n",
      "Epoch 374/2000\n",
      "8/8 [==============================] - 0s 675us/step - loss: 18.4244\n",
      "Epoch 375/2000\n",
      "8/8 [==============================] - 0s 591us/step - loss: 18.3991\n",
      "Epoch 376/2000\n",
      "8/8 [==============================] - 0s 652us/step - loss: 18.3664\n",
      "Epoch 377/2000\n",
      "8/8 [==============================] - 0s 594us/step - loss: 18.2600\n",
      "Epoch 378/2000\n",
      "8/8 [==============================] - 0s 582us/step - loss: 18.2256\n",
      "Epoch 379/2000\n",
      "8/8 [==============================] - 0s 593us/step - loss: 18.1691\n",
      "Epoch 380/2000\n",
      "8/8 [==============================] - 0s 620us/step - loss: 18.1078\n",
      "Epoch 381/2000\n",
      "8/8 [==============================] - 0s 610us/step - loss: 18.0688\n",
      "Epoch 382/2000\n",
      "8/8 [==============================] - 0s 715us/step - loss: 18.0264\n",
      "Epoch 383/2000\n",
      "8/8 [==============================] - 0s 644us/step - loss: 17.9966\n",
      "Epoch 384/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 17.9237\n",
      "Epoch 385/2000\n",
      "8/8 [==============================] - 0s 621us/step - loss: 17.8773\n",
      "Epoch 386/2000\n",
      "8/8 [==============================] - 0s 777us/step - loss: 17.8181\n",
      "Epoch 387/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 17.7772\n",
      "Epoch 388/2000\n",
      "8/8 [==============================] - 0s 878us/step - loss: 17.7382\n",
      "Epoch 389/2000\n",
      "8/8 [==============================] - 0s 703us/step - loss: 17.7223\n",
      "Epoch 390/2000\n",
      "8/8 [==============================] - 0s 836us/step - loss: 17.6822\n",
      "Epoch 391/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 17.6070\n",
      "Epoch 392/2000\n",
      "8/8 [==============================] - 0s 685us/step - loss: 17.5444\n",
      "Epoch 393/2000\n",
      "8/8 [==============================] - 0s 675us/step - loss: 17.4977\n",
      "Epoch 394/2000\n",
      "8/8 [==============================] - 0s 670us/step - loss: 17.4761\n",
      "Epoch 395/2000\n",
      "8/8 [==============================] - 0s 640us/step - loss: 17.4380\n",
      "Epoch 396/2000\n",
      "8/8 [==============================] - 0s 586us/step - loss: 17.3822\n",
      "Epoch 397/2000\n",
      "8/8 [==============================] - 0s 591us/step - loss: 17.4208\n",
      "Epoch 398/2000\n",
      "8/8 [==============================] - 0s 613us/step - loss: 17.3717\n",
      "Epoch 399/2000\n",
      "8/8 [==============================] - 0s 580us/step - loss: 17.2946\n",
      "Epoch 400/2000\n",
      "8/8 [==============================] - 0s 615us/step - loss: 17.2245\n",
      "Epoch 401/2000\n",
      "8/8 [==============================] - 0s 583us/step - loss: 17.1892\n",
      "Epoch 402/2000\n",
      "8/8 [==============================] - 0s 798us/step - loss: 17.1802\n",
      "Epoch 403/2000\n",
      "8/8 [==============================] - 0s 635us/step - loss: 17.1187\n",
      "Epoch 404/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 17.1514\n",
      "Epoch 405/2000\n",
      "8/8 [==============================] - 0s 770us/step - loss: 17.0040\n",
      "Epoch 406/2000\n",
      "8/8 [==============================] - 0s 674us/step - loss: 17.0735\n",
      "Epoch 407/2000\n",
      "8/8 [==============================] - 0s 632us/step - loss: 17.0968\n",
      "Epoch 408/2000\n",
      "8/8 [==============================] - 0s 613us/step - loss: 16.9478\n",
      "Epoch 409/2000\n",
      "8/8 [==============================] - 0s 797us/step - loss: 16.9287\n",
      "Epoch 410/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 16.8889\n",
      "Epoch 411/2000\n",
      "8/8 [==============================] - 0s 696us/step - loss: 16.8526\n",
      "Epoch 412/2000\n",
      "8/8 [==============================] - 0s 855us/step - loss: 16.7997\n",
      "Epoch 413/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 16.7673\n",
      "Epoch 414/2000\n",
      "8/8 [==============================] - 0s 684us/step - loss: 16.7590\n",
      "Epoch 415/2000\n",
      "8/8 [==============================] - 0s 797us/step - loss: 16.7413\n",
      "Epoch 416/2000\n",
      "8/8 [==============================] - 0s 688us/step - loss: 16.7166\n",
      "Epoch 417/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 16.6858\n",
      "Epoch 418/2000\n",
      "8/8 [==============================] - 0s 615us/step - loss: 16.6165\n",
      "Epoch 419/2000\n",
      "8/8 [==============================] - 0s 589us/step - loss: 16.6413\n",
      "Epoch 420/2000\n",
      "8/8 [==============================] - 0s 609us/step - loss: 16.5513\n",
      "Epoch 421/2000\n",
      "8/8 [==============================] - 0s 595us/step - loss: 16.5605\n",
      "Epoch 422/2000\n",
      "8/8 [==============================] - 0s 625us/step - loss: 16.5310\n",
      "Epoch 423/2000\n",
      "8/8 [==============================] - 0s 604us/step - loss: 16.4657\n",
      "Epoch 424/2000\n",
      "8/8 [==============================] - 0s 612us/step - loss: 16.4903\n",
      "Epoch 425/2000\n",
      "8/8 [==============================] - 0s 678us/step - loss: 16.4664\n",
      "Epoch 426/2000\n",
      "8/8 [==============================] - 0s 888us/step - loss: 16.4170\n",
      "Epoch 427/2000\n",
      "8/8 [==============================] - 0s 807us/step - loss: 16.4218\n",
      "Epoch 428/2000\n",
      "8/8 [==============================] - 0s 920us/step - loss: 16.3642\n",
      "Epoch 429/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 16.3466\n",
      "Epoch 430/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 16.3223\n",
      "Epoch 431/2000\n",
      "8/8 [==============================] - 0s 715us/step - loss: 16.3096\n",
      "Epoch 432/2000\n",
      "8/8 [==============================] - 0s 744us/step - loss: 16.2548\n",
      "Epoch 433/2000\n",
      "8/8 [==============================] - 0s 688us/step - loss: 16.2697\n",
      "Epoch 434/2000\n",
      "8/8 [==============================] - 0s 744us/step - loss: 16.2369\n",
      "Epoch 435/2000\n",
      "8/8 [==============================] - 0s 845us/step - loss: 16.2113\n",
      "Epoch 436/2000\n",
      "8/8 [==============================] - 0s 689us/step - loss: 16.1966\n",
      "Epoch 437/2000\n",
      "8/8 [==============================] - 0s 716us/step - loss: 16.1643\n",
      "Epoch 438/2000\n",
      "8/8 [==============================] - 0s 682us/step - loss: 16.1612\n",
      "Epoch 439/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 16.1503\n",
      "Epoch 440/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 16.1099\n",
      "Epoch 441/2000\n",
      "8/8 [==============================] - 0s 607us/step - loss: 16.1431\n",
      "Epoch 442/2000\n",
      "8/8 [==============================] - 0s 594us/step - loss: 16.0909\n",
      "Epoch 443/2000\n",
      "8/8 [==============================] - 0s 597us/step - loss: 16.1408\n",
      "Epoch 444/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 16.1369\n",
      "Epoch 445/2000\n",
      "8/8 [==============================] - 0s 626us/step - loss: 16.0273\n",
      "Epoch 446/2000\n",
      "8/8 [==============================] - 0s 607us/step - loss: 16.0447\n",
      "Epoch 447/2000\n",
      "8/8 [==============================] - 0s 638us/step - loss: 15.9967\n",
      "Epoch 448/2000\n",
      "8/8 [==============================] - 0s 605us/step - loss: 15.9843\n",
      "Epoch 449/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 15.9751\n",
      "Epoch 450/2000\n",
      "8/8 [==============================] - 0s 598us/step - loss: 15.9502\n",
      "Epoch 451/2000\n",
      "8/8 [==============================] - 0s 709us/step - loss: 15.9094\n",
      "Epoch 452/2000\n",
      "8/8 [==============================] - 0s 739us/step - loss: 15.9245\n",
      "Epoch 453/2000\n",
      "8/8 [==============================] - 0s 718us/step - loss: 15.8409\n",
      "Epoch 454/2000\n",
      "8/8 [==============================] - 0s 910us/step - loss: 15.9221\n",
      "Epoch 455/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 15.8297\n",
      "Epoch 456/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 15.8934\n",
      "Epoch 457/2000\n",
      "8/8 [==============================] - 0s 660us/step - loss: 15.8307\n",
      "Epoch 458/2000\n",
      "8/8 [==============================] - 0s 772us/step - loss: 15.8156\n",
      "Epoch 459/2000\n",
      "8/8 [==============================] - 0s 696us/step - loss: 15.8127\n",
      "Epoch 460/2000\n",
      "8/8 [==============================] - 0s 745us/step - loss: 15.7607\n",
      "Epoch 461/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 15.7899\n",
      "Epoch 462/2000\n",
      "8/8 [==============================] - 0s 741us/step - loss: 15.7576\n",
      "Epoch 463/2000\n",
      "8/8 [==============================] - 0s 605us/step - loss: 15.7712\n",
      "Epoch 464/2000\n",
      "8/8 [==============================] - 0s 612us/step - loss: 15.7429\n",
      "Epoch 465/2000\n",
      "8/8 [==============================] - 0s 597us/step - loss: 15.7402\n",
      "Epoch 466/2000\n",
      "8/8 [==============================] - 0s 589us/step - loss: 15.7147\n",
      "Epoch 467/2000\n",
      "8/8 [==============================] - 0s 592us/step - loss: 15.6849\n",
      "Epoch 468/2000\n",
      "8/8 [==============================] - 0s 578us/step - loss: 15.6902\n",
      "Epoch 469/2000\n",
      "8/8 [==============================] - 0s 654us/step - loss: 15.7045\n",
      "Epoch 470/2000\n",
      "8/8 [==============================] - 0s 605us/step - loss: 15.6686\n",
      "Epoch 471/2000\n",
      "8/8 [==============================] - 0s 586us/step - loss: 15.6003\n",
      "Epoch 472/2000\n",
      "8/8 [==============================] - 0s 591us/step - loss: 15.6589\n",
      "Epoch 473/2000\n",
      "8/8 [==============================] - 0s 612us/step - loss: 15.6605\n",
      "Epoch 474/2000\n",
      "8/8 [==============================] - 0s 603us/step - loss: 15.5781\n",
      "Epoch 475/2000\n",
      "8/8 [==============================] - 0s 580us/step - loss: 15.5714\n",
      "Epoch 476/2000\n",
      "8/8 [==============================] - 0s 599us/step - loss: 15.5615\n",
      "Epoch 477/2000\n",
      "8/8 [==============================] - 0s 582us/step - loss: 15.5471\n",
      "Epoch 478/2000\n",
      "8/8 [==============================] - 0s 594us/step - loss: 15.5219\n",
      "Epoch 479/2000\n",
      "8/8 [==============================] - 0s 582us/step - loss: 15.5297\n",
      "Epoch 480/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 15.5021\n",
      "Epoch 481/2000\n",
      "8/8 [==============================] - 0s 659us/step - loss: 15.4852\n",
      "Epoch 482/2000\n",
      "8/8 [==============================] - 0s 592us/step - loss: 15.4915\n",
      "Epoch 483/2000\n",
      "8/8 [==============================] - 0s 632us/step - loss: 15.4719\n",
      "Epoch 484/2000\n",
      "8/8 [==============================] - 0s 699us/step - loss: 15.4635\n",
      "Epoch 485/2000\n",
      "8/8 [==============================] - 0s 637us/step - loss: 15.4355\n",
      "Epoch 486/2000\n",
      "8/8 [==============================] - 0s 579us/step - loss: 15.4401\n",
      "Epoch 487/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 15.4291\n",
      "Epoch 488/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 15.4262\n",
      "Epoch 489/2000\n",
      "8/8 [==============================] - 0s 870us/step - loss: 15.4169\n",
      "Epoch 490/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 15.4378\n",
      "Epoch 491/2000\n",
      "8/8 [==============================] - 0s 715us/step - loss: 15.3645\n",
      "Epoch 492/2000\n",
      "8/8 [==============================] - 0s 827us/step - loss: 15.3544\n",
      "Epoch 493/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 15.3666\n",
      "Epoch 494/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 15.3252\n",
      "Epoch 495/2000\n",
      "8/8 [==============================] - 0s 647us/step - loss: 15.3621\n",
      "Epoch 496/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 15.3443\n",
      "Epoch 497/2000\n",
      "8/8 [==============================] - 0s 608us/step - loss: 15.3358\n",
      "Epoch 498/2000\n",
      "8/8 [==============================] - 0s 622us/step - loss: 15.3693\n",
      "Epoch 499/2000\n",
      "8/8 [==============================] - 0s 605us/step - loss: 15.4721\n",
      "Epoch 500/2000\n",
      "8/8 [==============================] - 0s 597us/step - loss: 15.3946\n",
      "Epoch 501/2000\n",
      "8/8 [==============================] - 0s 628us/step - loss: 15.2982\n",
      "Epoch 502/2000\n",
      "8/8 [==============================] - 0s 595us/step - loss: 15.3154\n",
      "Epoch 503/2000\n",
      "8/8 [==============================] - 0s 654us/step - loss: 15.3374\n",
      "Epoch 504/2000\n",
      "8/8 [==============================] - 0s 617us/step - loss: 15.2621\n",
      "Epoch 505/2000\n",
      "8/8 [==============================] - 0s 589us/step - loss: 15.2233\n",
      "Epoch 506/2000\n",
      "8/8 [==============================] - 0s 598us/step - loss: 15.2586\n",
      "Epoch 507/2000\n",
      "8/8 [==============================] - 0s 625us/step - loss: 15.2326\n",
      "Epoch 508/2000\n",
      "8/8 [==============================] - 0s 645us/step - loss: 15.1772\n",
      "Epoch 509/2000\n",
      "8/8 [==============================] - 0s 587us/step - loss: 15.2607\n",
      "Epoch 510/2000\n",
      "8/8 [==============================] - 0s 637us/step - loss: 15.2045\n",
      "Epoch 511/2000\n",
      "8/8 [==============================] - 0s 602us/step - loss: 15.2128\n",
      "Epoch 512/2000\n",
      "8/8 [==============================] - 0s 624us/step - loss: 15.2248\n",
      "Epoch 513/2000\n",
      "8/8 [==============================] - 0s 633us/step - loss: 15.2187\n",
      "Epoch 514/2000\n",
      "8/8 [==============================] - 0s 700us/step - loss: 15.1402\n",
      "Epoch 515/2000\n",
      "8/8 [==============================] - 0s 569us/step - loss: 15.1173\n",
      "Epoch 516/2000\n",
      "8/8 [==============================] - 0s 590us/step - loss: 15.1302\n",
      "Epoch 517/2000\n",
      "8/8 [==============================] - 0s 642us/step - loss: 15.1050\n",
      "Epoch 518/2000\n",
      "8/8 [==============================] - 0s 598us/step - loss: 15.1074\n",
      "Epoch 519/2000\n",
      "8/8 [==============================] - 0s 592us/step - loss: 15.0818\n",
      "Epoch 520/2000\n",
      "8/8 [==============================] - 0s 634us/step - loss: 15.0462\n",
      "Epoch 521/2000\n",
      "8/8 [==============================] - 0s 650us/step - loss: 15.0909\n",
      "Epoch 522/2000\n",
      "8/8 [==============================] - 0s 739us/step - loss: 15.0666\n",
      "Epoch 523/2000\n",
      "8/8 [==============================] - 0s 954us/step - loss: 15.0404\n",
      "Epoch 524/2000\n",
      "8/8 [==============================] - 0s 684us/step - loss: 15.0710\n",
      "Epoch 525/2000\n",
      "8/8 [==============================] - 0s 687us/step - loss: 15.0568\n",
      "Epoch 526/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 15.0053\n",
      "Epoch 527/2000\n",
      "8/8 [==============================] - 0s 628us/step - loss: 14.9891\n",
      "Epoch 528/2000\n",
      "8/8 [==============================] - 0s 683us/step - loss: 14.9997\n",
      "Epoch 529/2000\n",
      "8/8 [==============================] - 0s 630us/step - loss: 15.0030\n",
      "Epoch 530/2000\n",
      "8/8 [==============================] - 0s 615us/step - loss: 15.0499\n",
      "Epoch 531/2000\n",
      "8/8 [==============================] - 0s 639us/step - loss: 15.0250\n",
      "Epoch 532/2000\n",
      "8/8 [==============================] - 0s 831us/step - loss: 14.9297\n",
      "Epoch 533/2000\n",
      "8/8 [==============================] - 0s 706us/step - loss: 14.9520\n",
      "Epoch 534/2000\n",
      "8/8 [==============================] - 0s 756us/step - loss: 14.9430\n",
      "Epoch 535/2000\n",
      "8/8 [==============================] - 0s 859us/step - loss: 14.9293\n",
      "Epoch 536/2000\n",
      "8/8 [==============================] - 0s 817us/step - loss: 14.9608\n",
      "Epoch 537/2000\n",
      "8/8 [==============================] - 0s 761us/step - loss: 14.9168\n",
      "Epoch 538/2000\n",
      "8/8 [==============================] - 0s 689us/step - loss: 14.8968\n",
      "Epoch 539/2000\n",
      "8/8 [==============================] - 0s 777us/step - loss: 14.8959\n",
      "Epoch 540/2000\n",
      "8/8 [==============================] - 0s 919us/step - loss: 14.8861\n",
      "Epoch 541/2000\n",
      "8/8 [==============================] - 0s 739us/step - loss: 14.9007\n",
      "Epoch 542/2000\n",
      "8/8 [==============================] - 0s 722us/step - loss: 14.8475\n",
      "Epoch 543/2000\n",
      "8/8 [==============================] - 0s 713us/step - loss: 14.8390\n",
      "Epoch 544/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 14.8199\n",
      "Epoch 545/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 14.8314\n",
      "Epoch 546/2000\n",
      "8/8 [==============================] - 0s 731us/step - loss: 14.8215\n",
      "Epoch 547/2000\n",
      "8/8 [==============================] - 0s 634us/step - loss: 14.7861\n",
      "Epoch 548/2000\n",
      "8/8 [==============================] - 0s 591us/step - loss: 14.7992\n",
      "Epoch 549/2000\n",
      "8/8 [==============================] - 0s 622us/step - loss: 14.7602\n",
      "Epoch 550/2000\n",
      "8/8 [==============================] - 0s 609us/step - loss: 14.7517\n",
      "Epoch 551/2000\n",
      "8/8 [==============================] - 0s 643us/step - loss: 14.8781\n",
      "Epoch 552/2000\n",
      "8/8 [==============================] - 0s 795us/step - loss: 14.9279\n",
      "Epoch 553/2000\n",
      "8/8 [==============================] - 0s 717us/step - loss: 14.7801\n",
      "Epoch 554/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 14.7628\n",
      "Epoch 555/2000\n",
      "8/8 [==============================] - 0s 644us/step - loss: 14.7888\n",
      "Epoch 556/2000\n",
      "8/8 [==============================] - 0s 639us/step - loss: 14.7741\n",
      "Epoch 557/2000\n",
      "8/8 [==============================] - 0s 637us/step - loss: 14.7998\n",
      "Epoch 558/2000\n",
      "8/8 [==============================] - 0s 657us/step - loss: 14.8324\n",
      "Epoch 559/2000\n",
      "8/8 [==============================] - 0s 711us/step - loss: 14.7004\n",
      "Epoch 560/2000\n",
      "8/8 [==============================] - 0s 835us/step - loss: 14.6610\n",
      "Epoch 561/2000\n",
      "8/8 [==============================] - 0s 673us/step - loss: 14.6638\n",
      "Epoch 562/2000\n",
      "8/8 [==============================] - 0s 710us/step - loss: 14.6853\n",
      "Epoch 563/2000\n",
      "8/8 [==============================] - 0s 814us/step - loss: 14.6236\n",
      "Epoch 564/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 14.5888\n",
      "Epoch 565/2000\n",
      "8/8 [==============================] - 0s 673us/step - loss: 14.5975\n",
      "Epoch 566/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 14.5982\n",
      "Epoch 567/2000\n",
      "8/8 [==============================] - 0s 619us/step - loss: 14.5937\n",
      "Epoch 568/2000\n",
      "8/8 [==============================] - 0s 610us/step - loss: 14.6253\n",
      "Epoch 569/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 14.5687\n",
      "Epoch 570/2000\n",
      "8/8 [==============================] - 0s 596us/step - loss: 14.5283\n",
      "Epoch 571/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 14.6465\n",
      "Epoch 572/2000\n",
      "8/8 [==============================] - 0s 649us/step - loss: 14.5392\n",
      "Epoch 573/2000\n",
      "8/8 [==============================] - 0s 668us/step - loss: 14.4893\n",
      "Epoch 574/2000\n",
      "8/8 [==============================] - 0s 624us/step - loss: 14.4552\n",
      "Epoch 575/2000\n",
      "8/8 [==============================] - 0s 820us/step - loss: 14.4695\n",
      "Epoch 576/2000\n",
      "8/8 [==============================] - 0s 724us/step - loss: 14.4246\n",
      "Epoch 577/2000\n",
      "8/8 [==============================] - 0s 691us/step - loss: 14.4350\n",
      "Epoch 578/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 14.4323\n",
      "Epoch 579/2000\n",
      "8/8 [==============================] - 0s 618us/step - loss: 14.4073\n",
      "Epoch 580/2000\n",
      "8/8 [==============================] - 0s 588us/step - loss: 14.4824\n",
      "Epoch 581/2000\n",
      "8/8 [==============================] - 0s 621us/step - loss: 14.4750\n",
      "Epoch 582/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 14.3821\n",
      "Epoch 583/2000\n",
      "8/8 [==============================] - 0s 596us/step - loss: 14.4022\n",
      "Epoch 584/2000\n",
      "8/8 [==============================] - 0s 666us/step - loss: 14.4584\n",
      "Epoch 585/2000\n",
      "8/8 [==============================] - 0s 672us/step - loss: 14.3399\n",
      "Epoch 586/2000\n",
      "8/8 [==============================] - 0s 612us/step - loss: 14.4630\n",
      "Epoch 587/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 14.4856\n",
      "Epoch 588/2000\n",
      "8/8 [==============================] - 0s 790us/step - loss: 14.3919\n",
      "Epoch 589/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 14.2819\n",
      "Epoch 590/2000\n",
      "8/8 [==============================] - 0s 777us/step - loss: 14.3429\n",
      "Epoch 591/2000\n",
      "8/8 [==============================] - 0s 721us/step - loss: 14.2897\n",
      "Epoch 592/2000\n",
      "8/8 [==============================] - 0s 884us/step - loss: 14.2312\n",
      "Epoch 593/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.2842\n",
      "Epoch 594/2000\n",
      "8/8 [==============================] - 0s 919us/step - loss: 14.2425\n",
      "Epoch 595/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.2632\n",
      "Epoch 596/2000\n",
      "8/8 [==============================] - 0s 933us/step - loss: 14.3270\n",
      "Epoch 597/2000\n",
      "8/8 [==============================] - 0s 894us/step - loss: 14.1806\n",
      "Epoch 598/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.2230\n",
      "Epoch 599/2000\n",
      "8/8 [==============================] - 0s 835us/step - loss: 14.1814\n",
      "Epoch 600/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.2380\n",
      "Epoch 601/2000\n",
      "8/8 [==============================] - 0s 811us/step - loss: 14.2150\n",
      "Epoch 602/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.1260\n",
      "Epoch 603/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.1519\n",
      "Epoch 604/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.1351\n",
      "Epoch 605/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.1140\n",
      "Epoch 606/2000\n",
      "8/8 [==============================] - 0s 871us/step - loss: 14.1219\n",
      "Epoch 607/2000\n",
      "8/8 [==============================] - 0s 908us/step - loss: 14.0769\n",
      "Epoch 608/2000\n",
      "8/8 [==============================] - 0s 942us/step - loss: 14.0985\n",
      "Epoch 609/2000\n",
      "8/8 [==============================] - 0s 833us/step - loss: 14.0986\n",
      "Epoch 610/2000\n",
      "8/8 [==============================] - 0s 950us/step - loss: 14.0400\n",
      "Epoch 611/2000\n",
      "8/8 [==============================] - 0s 772us/step - loss: 14.0224\n",
      "Epoch 612/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.0434\n",
      "Epoch 613/2000\n",
      "8/8 [==============================] - 0s 885us/step - loss: 14.0216\n",
      "Epoch 614/2000\n",
      "8/8 [==============================] - 0s 945us/step - loss: 13.9992\n",
      "Epoch 615/2000\n",
      "8/8 [==============================] - 0s 740us/step - loss: 14.0171\n",
      "Epoch 616/2000\n",
      "8/8 [==============================] - 0s 769us/step - loss: 13.9500\n",
      "Epoch 617/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 14.0036\n",
      "Epoch 618/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 14.0305\n",
      "Epoch 619/2000\n",
      "8/8 [==============================] - 0s 736us/step - loss: 14.0344\n",
      "Epoch 620/2000\n",
      "8/8 [==============================] - 0s 758us/step - loss: 13.9397\n",
      "Epoch 621/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 13.9053\n",
      "Epoch 622/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 13.9696\n",
      "Epoch 623/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 13.9970\n",
      "Epoch 624/2000\n",
      "8/8 [==============================] - 0s 641us/step - loss: 13.8903\n",
      "Epoch 625/2000\n",
      "8/8 [==============================] - 0s 585us/step - loss: 13.8691\n",
      "Epoch 626/2000\n",
      "8/8 [==============================] - 0s 588us/step - loss: 13.9038\n",
      "Epoch 627/2000\n",
      "8/8 [==============================] - 0s 633us/step - loss: 13.8771\n",
      "Epoch 628/2000\n",
      "8/8 [==============================] - 0s 629us/step - loss: 13.8230\n",
      "Epoch 629/2000\n",
      "8/8 [==============================] - 0s 590us/step - loss: 13.9183\n",
      "Epoch 630/2000\n",
      "8/8 [==============================] - 0s 649us/step - loss: 13.8175\n",
      "Epoch 631/2000\n",
      "8/8 [==============================] - 0s 599us/step - loss: 13.7969\n",
      "Epoch 632/2000\n",
      "8/8 [==============================] - 0s 628us/step - loss: 13.7665\n",
      "Epoch 633/2000\n",
      "8/8 [==============================] - 0s 601us/step - loss: 13.8083\n",
      "Epoch 634/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 13.8782\n",
      "Epoch 635/2000\n",
      "8/8 [==============================] - 0s 640us/step - loss: 13.7609\n",
      "Epoch 636/2000\n",
      "8/8 [==============================] - 0s 653us/step - loss: 13.7594\n",
      "Epoch 637/2000\n",
      "8/8 [==============================] - 0s 595us/step - loss: 13.7298\n",
      "Epoch 638/2000\n",
      "8/8 [==============================] - 0s 768us/step - loss: 13.7424\n",
      "Epoch 639/2000\n",
      "8/8 [==============================] - 0s 722us/step - loss: 13.6677\n",
      "Epoch 640/2000\n",
      "8/8 [==============================] - 0s 848us/step - loss: 13.6988\n",
      "Epoch 641/2000\n",
      "8/8 [==============================] - 0s 765us/step - loss: 13.7082\n",
      "Epoch 642/2000\n",
      "8/8 [==============================] - 0s 755us/step - loss: 13.6874\n",
      "Epoch 643/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.6691\n",
      "Epoch 644/2000\n",
      "8/8 [==============================] - 0s 815us/step - loss: 13.7484\n",
      "Epoch 645/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.6429\n",
      "Epoch 646/2000\n",
      "8/8 [==============================] - 0s 827us/step - loss: 13.6971\n",
      "Epoch 647/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.6503\n",
      "Epoch 648/2000\n",
      "8/8 [==============================] - 0s 874us/step - loss: 13.5887\n",
      "Epoch 649/2000\n",
      "8/8 [==============================] - 0s 905us/step - loss: 13.6356\n",
      "Epoch 650/2000\n",
      "8/8 [==============================] - 0s 900us/step - loss: 13.6111\n",
      "Epoch 651/2000\n",
      "8/8 [==============================] - 0s 890us/step - loss: 13.7905\n",
      "Epoch 652/2000\n",
      "8/8 [==============================] - 0s 974us/step - loss: 13.5852\n",
      "Epoch 653/2000\n",
      "8/8 [==============================] - 0s 772us/step - loss: 13.5572\n",
      "Epoch 654/2000\n",
      "8/8 [==============================] - 0s 698us/step - loss: 13.5740\n",
      "Epoch 655/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 13.5250\n",
      "Epoch 656/2000\n",
      "8/8 [==============================] - 0s 740us/step - loss: 13.6039\n",
      "Epoch 657/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 13.4879\n",
      "Epoch 658/2000\n",
      "8/8 [==============================] - 0s 699us/step - loss: 13.5171\n",
      "Epoch 659/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 13.4699\n",
      "Epoch 660/2000\n",
      "8/8 [==============================] - 0s 604us/step - loss: 13.4743\n",
      "Epoch 661/2000\n",
      "8/8 [==============================] - 0s 699us/step - loss: 13.5149\n",
      "Epoch 662/2000\n",
      "8/8 [==============================] - 0s 778us/step - loss: 13.4616\n",
      "Epoch 663/2000\n",
      "8/8 [==============================] - 0s 731us/step - loss: 13.4656\n",
      "Epoch 664/2000\n",
      "8/8 [==============================] - 0s 871us/step - loss: 13.5560\n",
      "Epoch 665/2000\n",
      "8/8 [==============================] - 0s 772us/step - loss: 13.4603\n",
      "Epoch 666/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.4520\n",
      "Epoch 667/2000\n",
      "8/8 [==============================] - 0s 825us/step - loss: 13.4505\n",
      "Epoch 668/2000\n",
      "8/8 [==============================] - 0s 905us/step - loss: 13.3873\n",
      "Epoch 669/2000\n",
      "8/8 [==============================] - 0s 969us/step - loss: 13.3547\n",
      "Epoch 670/2000\n",
      "8/8 [==============================] - 0s 824us/step - loss: 13.3680\n",
      "Epoch 671/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.4218\n",
      "Epoch 672/2000\n",
      "8/8 [==============================] - 0s 908us/step - loss: 13.3263\n",
      "Epoch 673/2000\n",
      "8/8 [==============================] - 0s 1000us/step - loss: 13.3628\n",
      "Epoch 674/2000\n",
      "8/8 [==============================] - 0s 865us/step - loss: 13.3612\n",
      "Epoch 675/2000\n",
      "8/8 [==============================] - 0s 870us/step - loss: 13.3300\n",
      "Epoch 676/2000\n",
      "8/8 [==============================] - 0s 812us/step - loss: 13.3800\n",
      "Epoch 677/2000\n",
      "8/8 [==============================] - 0s 876us/step - loss: 13.3254\n",
      "Epoch 678/2000\n",
      "8/8 [==============================] - 0s 886us/step - loss: 13.2913\n",
      "Epoch 679/2000\n",
      "8/8 [==============================] - 0s 817us/step - loss: 13.3640\n",
      "Epoch 680/2000\n",
      "8/8 [==============================] - 0s 896us/step - loss: 13.3396\n",
      "Epoch 681/2000\n",
      "8/8 [==============================] - 0s 878us/step - loss: 13.3541\n",
      "Epoch 682/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.3967\n",
      "Epoch 683/2000\n",
      "8/8 [==============================] - 0s 885us/step - loss: 13.3336\n",
      "Epoch 684/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13.2427\n",
      "Epoch 685/2000\n",
      "8/8 [==============================] - 0s 773us/step - loss: 13.2470\n",
      "Epoch 686/2000\n",
      "8/8 [==============================] - 0s 986us/step - loss: 13.2031\n",
      "Epoch 687/2000\n",
      "8/8 [==============================] - 0s 761us/step - loss: 13.1680\n",
      "Epoch 688/2000\n",
      "8/8 [==============================] - 0s 849us/step - loss: 13.1926\n",
      "Epoch 689/2000\n",
      "8/8 [==============================] - 0s 777us/step - loss: 13.1845\n",
      "Epoch 690/2000\n",
      "8/8 [==============================] - 0s 956us/step - loss: 13.1600\n",
      "Epoch 691/2000\n",
      "8/8 [==============================] - 0s 840us/step - loss: 13.1918\n",
      "Epoch 692/2000\n",
      "8/8 [==============================] - 0s 858us/step - loss: 13.1774\n",
      "Epoch 693/2000\n",
      "8/8 [==============================] - 0s 909us/step - loss: 13.1152\n",
      "Epoch 694/2000\n",
      "8/8 [==============================] - 0s 764us/step - loss: 13.1448\n",
      "Epoch 695/2000\n",
      "8/8 [==============================] - 0s 832us/step - loss: 13.1390\n",
      "Epoch 696/2000\n",
      "8/8 [==============================] - 0s 819us/step - loss: 13.0733\n",
      "Epoch 697/2000\n",
      "8/8 [==============================] - 0s 816us/step - loss: 13.0626\n",
      "Epoch 698/2000\n",
      "8/8 [==============================] - 0s 750us/step - loss: 13.0348\n",
      "Epoch 699/2000\n",
      "8/8 [==============================] - 0s 817us/step - loss: 13.0814\n",
      "Epoch 700/2000\n",
      "8/8 [==============================] - 0s 817us/step - loss: 13.0730\n",
      "Epoch 701/2000\n",
      "8/8 [==============================] - 0s 974us/step - loss: 13.0370\n",
      "Epoch 702/2000\n",
      "8/8 [==============================] - 0s 767us/step - loss: 13.1018\n",
      "Epoch 703/2000\n",
      "8/8 [==============================] - 0s 931us/step - loss: 13.0520\n",
      "Epoch 704/2000\n",
      "8/8 [==============================] - 0s 826us/step - loss: 13.0541\n",
      "Epoch 705/2000\n",
      "8/8 [==============================] - 0s 925us/step - loss: 12.9685\n",
      "Epoch 706/2000\n",
      "8/8 [==============================] - 0s 734us/step - loss: 13.0043\n",
      "Epoch 707/2000\n",
      "8/8 [==============================] - 0s 846us/step - loss: 13.1154\n",
      "Epoch 708/2000\n",
      "8/8 [==============================] - 0s 735us/step - loss: 13.0068\n",
      "Epoch 709/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 13.0050\n",
      "Epoch 710/2000\n",
      "8/8 [==============================] - 0s 824us/step - loss: 13.0996\n",
      "Epoch 711/2000\n",
      "8/8 [==============================] - 0s 742us/step - loss: 13.1082\n",
      "Epoch 712/2000\n",
      "8/8 [==============================] - 0s 966us/step - loss: 12.9674\n",
      "Epoch 713/2000\n",
      "8/8 [==============================] - 0s 768us/step - loss: 12.9863\n",
      "Epoch 714/2000\n",
      "8/8 [==============================] - 0s 896us/step - loss: 13.0357\n",
      "Epoch 715/2000\n",
      "8/8 [==============================] - 0s 786us/step - loss: 12.9516\n",
      "Epoch 716/2000\n",
      "8/8 [==============================] - 0s 851us/step - loss: 13.0230\n",
      "Epoch 717/2000\n",
      "8/8 [==============================] - 0s 763us/step - loss: 12.9325\n",
      "Epoch 718/2000\n",
      "8/8 [==============================] - 0s 862us/step - loss: 12.8816\n",
      "Epoch 719/2000\n",
      "8/8 [==============================] - 0s 736us/step - loss: 12.9493\n",
      "Epoch 720/2000\n",
      "8/8 [==============================] - 0s 864us/step - loss: 12.9006\n",
      "Epoch 721/2000\n",
      "8/8 [==============================] - 0s 780us/step - loss: 12.9649\n",
      "Epoch 722/2000\n",
      "8/8 [==============================] - 0s 901us/step - loss: 12.9181\n",
      "Epoch 723/2000\n",
      "8/8 [==============================] - 0s 730us/step - loss: 12.8779\n",
      "Epoch 724/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 12.8513\n",
      "Epoch 725/2000\n",
      "8/8 [==============================] - 0s 708us/step - loss: 12.8731\n",
      "Epoch 726/2000\n",
      "8/8 [==============================] - 0s 711us/step - loss: 12.8589\n",
      "Epoch 727/2000\n",
      "8/8 [==============================] - 0s 655us/step - loss: 12.8145\n",
      "Epoch 728/2000\n",
      "8/8 [==============================] - 0s 594us/step - loss: 12.8289\n",
      "Epoch 729/2000\n",
      "8/8 [==============================] - 0s 645us/step - loss: 12.7829\n",
      "Epoch 730/2000\n",
      "8/8 [==============================] - 0s 617us/step - loss: 12.7942\n",
      "Epoch 731/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 12.7554\n",
      "Epoch 732/2000\n",
      "8/8 [==============================] - 0s 618us/step - loss: 12.7347\n",
      "Epoch 733/2000\n",
      "8/8 [==============================] - 0s 636us/step - loss: 12.7907\n",
      "Epoch 734/2000\n",
      "8/8 [==============================] - 0s 638us/step - loss: 12.7703\n",
      "Epoch 735/2000\n",
      "8/8 [==============================] - 0s 629us/step - loss: 12.7312\n",
      "Epoch 736/2000\n",
      "8/8 [==============================] - 0s 632us/step - loss: 12.7139\n",
      "Epoch 737/2000\n",
      "8/8 [==============================] - 0s 588us/step - loss: 12.7190\n",
      "Epoch 738/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 12.7585\n",
      "Epoch 739/2000\n",
      "8/8 [==============================] - 0s 889us/step - loss: 12.6958\n",
      "Epoch 740/2000\n",
      "8/8 [==============================] - 0s 735us/step - loss: 12.7036\n",
      "Epoch 741/2000\n",
      "8/8 [==============================] - 0s 994us/step - loss: 12.7576\n",
      "Epoch 742/2000\n",
      "8/8 [==============================] - 0s 755us/step - loss: 12.8408\n",
      "Epoch 743/2000\n",
      "8/8 [==============================] - 0s 806us/step - loss: 12.7627\n",
      "Epoch 744/2000\n",
      "8/8 [==============================] - 0s 961us/step - loss: 12.6571\n",
      "Epoch 745/2000\n",
      "8/8 [==============================] - 0s 804us/step - loss: 12.6153\n",
      "Epoch 746/2000\n",
      "8/8 [==============================] - 0s 780us/step - loss: 12.6084\n",
      "Epoch 747/2000\n",
      "8/8 [==============================] - 0s 843us/step - loss: 12.6449\n",
      "Epoch 748/2000\n",
      "8/8 [==============================] - 0s 779us/step - loss: 12.7641\n",
      "Epoch 749/2000\n",
      "8/8 [==============================] - 0s 772us/step - loss: 12.6440\n",
      "Epoch 750/2000\n",
      "8/8 [==============================] - 0s 821us/step - loss: 12.5277\n",
      "Epoch 751/2000\n",
      "8/8 [==============================] - 0s 783us/step - loss: 12.5369\n",
      "Epoch 752/2000\n",
      "8/8 [==============================] - 0s 827us/step - loss: 12.6566\n",
      "Epoch 753/2000\n",
      "8/8 [==============================] - 0s 746us/step - loss: 12.5332\n",
      "Epoch 754/2000\n",
      "8/8 [==============================] - 0s 764us/step - loss: 12.5362\n",
      "Epoch 755/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 12.5273\n",
      "Epoch 756/2000\n",
      "8/8 [==============================] - 0s 658us/step - loss: 12.5535\n",
      "Epoch 757/2000\n",
      "8/8 [==============================] - 0s 603us/step - loss: 12.5413\n",
      "Epoch 758/2000\n",
      "8/8 [==============================] - 0s 631us/step - loss: 12.6561\n",
      "Epoch 759/2000\n",
      "8/8 [==============================] - 0s 620us/step - loss: 12.6068\n",
      "Epoch 760/2000\n",
      "8/8 [==============================] - 0s 617us/step - loss: 12.5492\n",
      "Epoch 761/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 12.5300\n",
      "Epoch 762/2000\n",
      "8/8 [==============================] - 0s 634us/step - loss: 12.6298\n",
      "Epoch 763/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 12.5865\n",
      "Epoch 764/2000\n",
      "8/8 [==============================] - 0s 603us/step - loss: 12.5767\n",
      "Epoch 765/2000\n",
      "8/8 [==============================] - 0s 615us/step - loss: 12.7849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff3f986a640>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "mlp.fit(df2.drop('Sen2.5', axis=1).drop([\"Raster.Cell\", \"x\", \"y\"], axis=1), df2['Sen2.5'], epochs=2000, batch_size=200, callbacks=[stopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting seems reasonable; some changes, like removing outliers, scaling variables are missing, so needs work yet to match the base model. We will do that work as we implement the IPW loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mse(y_true, y_pred, weight):\n",
    "    return weight * mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    resets the neural net model for each fold\n",
    "    \"\"\"\n",
    "    # input tensors; the last 2 are psuedo-inputs to use for the loss\n",
    "    mlp = Input(shape=(31,))\n",
    "    y_true = Input(shape=(1,))\n",
    "    weight = Input(shape=(1,))\n",
    "    \n",
    "    # here we use the Model framework, instead of Sequential, as the model has multiple pseudo-inputs\n",
    "    x = Dense(10, activation=\"relu\")(mlp)\n",
    "    x = Dense(10, activation=\"relu\")(x)\n",
    "    y_pred = Dense(1)(mlp)\n",
    "    model = Model(inputs=[mlp, y_true, weight], outputs=y_pred)\n",
    "    model.add_loss(weighted_mse(y_true, y_pred, weight))\n",
    "    model.compile(loss=None, optimizer=\"adam\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "8/8 [==============================] - 0s 836us/step - loss: 396921.9688\n",
      "Epoch 2/2000\n",
      "8/8 [==============================] - 0s 593us/step - loss: 303017.1875\n",
      "Epoch 3/2000\n",
      "8/8 [==============================] - 0s 574us/step - loss: 231860.5312\n",
      "Epoch 4/2000\n",
      "8/8 [==============================] - 0s 606us/step - loss: 170617.1875\n",
      "Epoch 5/2000\n",
      "8/8 [==============================] - 0s 948us/step - loss: 129357.6094\n",
      "Epoch 6/2000\n",
      "8/8 [==============================] - 0s 703us/step - loss: 90878.5938\n",
      "Epoch 7/2000\n",
      "8/8 [==============================] - 0s 816us/step - loss: 68344.0156\n",
      "Epoch 8/2000\n",
      "8/8 [==============================] - 0s 973us/step - loss: 49734.0352\n",
      "Epoch 9/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 37760.5234\n",
      "Epoch 10/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 29234.6035\n",
      "Epoch 11/2000\n",
      "8/8 [==============================] - 0s 884us/step - loss: 23506.3984\n",
      "Epoch 12/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 19821.7988\n",
      "Epoch 13/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 17381.0156\n",
      "Epoch 14/2000\n",
      "8/8 [==============================] - 0s 971us/step - loss: 15264.8369\n",
      "Epoch 15/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 13788.1992\n",
      "Epoch 16/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 12318.4346\n",
      "Epoch 17/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 11034.1553\n",
      "Epoch 18/2000\n",
      "8/8 [==============================] - 0s 974us/step - loss: 9847.7441\n",
      "Epoch 19/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 9095.9209\n",
      "Epoch 20/2000\n",
      "8/8 [==============================] - 0s 785us/step - loss: 8326.0762\n",
      "Epoch 21/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 7570.3589\n",
      "Epoch 22/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 7088.6250\n",
      "Epoch 23/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 6569.3735\n",
      "Epoch 24/2000\n",
      "8/8 [==============================] - 0s 950us/step - loss: 6087.2563\n",
      "Epoch 25/2000\n",
      "8/8 [==============================] - 0s 797us/step - loss: 5604.0254\n",
      "Epoch 26/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 5288.2534\n",
      "Epoch 27/2000\n",
      "8/8 [==============================] - 0s 818us/step - loss: 4926.7617\n",
      "Epoch 28/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4689.6484\n",
      "Epoch 29/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4465.3281\n",
      "Epoch 30/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 4233.9282\n",
      "Epoch 31/2000\n",
      "8/8 [==============================] - 0s 771us/step - loss: 4018.6389\n",
      "Epoch 32/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3826.1375\n",
      "Epoch 33/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3626.3723\n",
      "Epoch 34/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3452.2642\n",
      "Epoch 35/2000\n",
      "8/8 [==============================] - 0s 765us/step - loss: 3294.1196\n",
      "Epoch 36/2000\n",
      "8/8 [==============================] - 0s 815us/step - loss: 3141.9468\n",
      "Epoch 37/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 3043.3928\n",
      "Epoch 38/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2872.4363\n",
      "Epoch 39/2000\n",
      "8/8 [==============================] - 0s 751us/step - loss: 2747.2920\n",
      "Epoch 40/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2620.5120\n",
      "Epoch 41/2000\n",
      "8/8 [==============================] - 0s 781us/step - loss: 2496.6157\n",
      "Epoch 42/2000\n",
      "8/8 [==============================] - 0s 924us/step - loss: 2372.3391\n",
      "Epoch 43/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2285.3237\n",
      "Epoch 44/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2165.1731\n",
      "Epoch 45/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 2066.4551\n",
      "Epoch 46/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1963.1561\n",
      "Epoch 47/2000\n",
      "8/8 [==============================] - 0s 852us/step - loss: 1871.5646\n",
      "Epoch 48/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1776.8387\n",
      "Epoch 49/2000\n",
      "8/8 [==============================] - 0s 890us/step - loss: 1708.0000\n",
      "Epoch 50/2000\n",
      "8/8 [==============================] - 0s 789us/step - loss: 1609.8596\n",
      "Epoch 51/2000\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 1536.3617\n",
      "Epoch 52/2000\n",
      "8/8 [==============================] - 0s 840us/step - loss: 1451.3021\n",
      "Epoch 53/2000\n",
      "8/8 [==============================] - 0s 838us/step - loss: 1374.2383\n",
      "Epoch 54/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1321.5973\n",
      "Epoch 55/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1252.1895\n",
      "Epoch 56/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1184.8236\n",
      "Epoch 57/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 1111.8850\n",
      "Epoch 58/2000\n",
      "8/8 [==============================] - 0s 904us/step - loss: 1069.4424\n",
      "Epoch 59/2000\n",
      "8/8 [==============================] - 0s 775us/step - loss: 1005.2793\n",
      "Epoch 60/2000\n",
      "8/8 [==============================] - 0s 831us/step - loss: 958.4430\n",
      "Epoch 61/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 896.3494\n",
      "Epoch 62/2000\n",
      "8/8 [==============================] - 0s 757us/step - loss: 853.8373\n",
      "Epoch 63/2000\n",
      "8/8 [==============================] - 0s 839us/step - loss: 804.6422\n",
      "Epoch 64/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 764.9827\n",
      "Epoch 65/2000\n",
      "8/8 [==============================] - 0s 929us/step - loss: 729.9079\n",
      "Epoch 66/2000\n",
      "8/8 [==============================] - 0s 832us/step - loss: 681.9084\n",
      "Epoch 67/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 645.2142\n",
      "Epoch 68/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 610.0852\n",
      "Epoch 69/2000\n",
      "8/8 [==============================] - 0s 826us/step - loss: 577.3226\n",
      "Epoch 70/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 545.6854\n",
      "Epoch 71/2000\n",
      "8/8 [==============================] - 0s 781us/step - loss: 515.6412\n",
      "Epoch 72/2000\n",
      "8/8 [==============================] - 0s 909us/step - loss: 484.8580\n",
      "Epoch 73/2000\n",
      "8/8 [==============================] - 0s 876us/step - loss: 456.3800\n",
      "Epoch 74/2000\n",
      "8/8 [==============================] - 0s 928us/step - loss: 429.8223\n",
      "Epoch 75/2000\n",
      "8/8 [==============================] - 0s 924us/step - loss: 409.1576\n",
      "Epoch 76/2000\n",
      "8/8 [==============================] - 0s 783us/step - loss: 389.6013\n",
      "Epoch 77/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 366.5892\n",
      "Epoch 78/2000\n",
      "8/8 [==============================] - 0s 820us/step - loss: 346.5328\n",
      "Epoch 79/2000\n",
      "8/8 [==============================] - 0s 714us/step - loss: 327.2760\n",
      "Epoch 80/2000\n",
      "8/8 [==============================] - 0s 832us/step - loss: 311.7460\n",
      "Epoch 81/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 295.2870\n",
      "Epoch 82/2000\n",
      "8/8 [==============================] - 0s 927us/step - loss: 275.3183\n",
      "Epoch 83/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 262.5817\n",
      "Epoch 84/2000\n",
      "8/8 [==============================] - 0s 810us/step - loss: 249.3802\n",
      "Epoch 85/2000\n",
      "8/8 [==============================] - 0s 752us/step - loss: 238.0707\n",
      "Epoch 86/2000\n",
      "8/8 [==============================] - 0s 871us/step - loss: 225.6285\n",
      "Epoch 87/2000\n",
      "8/8 [==============================] - 0s 909us/step - loss: 213.8438\n",
      "Epoch 88/2000\n",
      "8/8 [==============================] - 0s 750us/step - loss: 203.7921\n",
      "Epoch 89/2000\n",
      "8/8 [==============================] - 0s 806us/step - loss: 192.2603\n",
      "Epoch 90/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 182.4519\n",
      "Epoch 91/2000\n",
      "8/8 [==============================] - 0s 728us/step - loss: 176.0355\n",
      "Epoch 92/2000\n",
      "8/8 [==============================] - 0s 736us/step - loss: 167.7559\n",
      "Epoch 93/2000\n",
      "8/8 [==============================] - 0s 900us/step - loss: 157.9484\n",
      "Epoch 94/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 153.4115\n",
      "Epoch 95/2000\n",
      "8/8 [==============================] - 0s 995us/step - loss: 145.6211\n",
      "Epoch 96/2000\n",
      "8/8 [==============================] - 0s 744us/step - loss: 140.6820\n",
      "Epoch 97/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 135.9874\n",
      "Epoch 98/2000\n",
      "8/8 [==============================] - 0s 847us/step - loss: 130.6938\n",
      "Epoch 99/2000\n",
      "8/8 [==============================] - 0s 720us/step - loss: 126.6325\n",
      "Epoch 100/2000\n",
      "8/8 [==============================] - 0s 798us/step - loss: 121.4836\n",
      "Epoch 101/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 116.9928\n",
      "Epoch 102/2000\n",
      "8/8 [==============================] - 0s 762us/step - loss: 113.0079\n",
      "Epoch 103/2000\n",
      "8/8 [==============================] - 0s 965us/step - loss: 108.0970\n",
      "Epoch 104/2000\n",
      "8/8 [==============================] - 0s 788us/step - loss: 106.9517\n",
      "Epoch 105/2000\n",
      "8/8 [==============================] - 0s 755us/step - loss: 103.2623\n",
      "Epoch 106/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 100.3173\n",
      "Epoch 107/2000\n",
      "8/8 [==============================] - 0s 771us/step - loss: 98.1898\n",
      "Epoch 108/2000\n",
      "8/8 [==============================] - 0s 762us/step - loss: 96.3369\n",
      "Epoch 109/2000\n",
      "8/8 [==============================] - 0s 837us/step - loss: 93.2047\n",
      "Epoch 110/2000\n",
      "8/8 [==============================] - 0s 933us/step - loss: 90.8277\n",
      "Epoch 111/2000\n",
      "8/8 [==============================] - 0s 749us/step - loss: 89.0749\n",
      "Epoch 112/2000\n",
      "8/8 [==============================] - 0s 949us/step - loss: 87.9130\n",
      "Epoch 113/2000\n",
      "8/8 [==============================] - 0s 730us/step - loss: 86.3485\n",
      "Epoch 114/2000\n",
      "8/8 [==============================] - 0s 938us/step - loss: 83.8822\n",
      "Epoch 115/2000\n",
      "8/8 [==============================] - 0s 823us/step - loss: 83.3698\n",
      "Epoch 116/2000\n",
      "8/8 [==============================] - 0s 767us/step - loss: 81.8378\n",
      "Epoch 117/2000\n",
      "8/8 [==============================] - 0s 801us/step - loss: 80.7689\n",
      "Epoch 118/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 79.8636\n",
      "Epoch 119/2000\n",
      "8/8 [==============================] - 0s 755us/step - loss: 78.4215\n",
      "Epoch 120/2000\n",
      "8/8 [==============================] - 0s 758us/step - loss: 77.2013\n",
      "Epoch 121/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 77.1343\n",
      "Epoch 122/2000\n",
      "8/8 [==============================] - 0s 890us/step - loss: 74.9932\n",
      "Epoch 123/2000\n",
      "8/8 [==============================] - 0s 969us/step - loss: 75.7793\n",
      "Epoch 124/2000\n",
      "8/8 [==============================] - 0s 754us/step - loss: 74.2049\n",
      "Epoch 125/2000\n",
      "8/8 [==============================] - 0s 888us/step - loss: 74.3726\n",
      "Epoch 126/2000\n",
      "8/8 [==============================] - 0s 882us/step - loss: 73.9372\n",
      "Epoch 127/2000\n",
      "8/8 [==============================] - 0s 938us/step - loss: 73.0196\n",
      "Epoch 128/2000\n",
      "8/8 [==============================] - 0s 807us/step - loss: 72.3276\n",
      "Epoch 129/2000\n",
      "8/8 [==============================] - 0s 769us/step - loss: 71.7024\n",
      "Epoch 130/2000\n",
      "8/8 [==============================] - 0s 954us/step - loss: 70.6422\n",
      "Epoch 131/2000\n",
      "8/8 [==============================] - 0s 782us/step - loss: 71.4239\n",
      "Epoch 132/2000\n",
      "8/8 [==============================] - 0s 814us/step - loss: 71.1404\n",
      "Epoch 133/2000\n",
      "8/8 [==============================] - 0s 774us/step - loss: 70.8658\n",
      "Epoch 134/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 70.1394\n",
      "Epoch 135/2000\n",
      "8/8 [==============================] - 0s 922us/step - loss: 70.2081\n",
      "Epoch 136/2000\n",
      "8/8 [==============================] - 0s 817us/step - loss: 69.6814\n",
      "Epoch 137/2000\n",
      "8/8 [==============================] - 0s 749us/step - loss: 69.3474\n",
      "Epoch 138/2000\n",
      "8/8 [==============================] - 0s 896us/step - loss: 69.2048\n",
      "Epoch 139/2000\n",
      "8/8 [==============================] - 0s 918us/step - loss: 68.8168\n",
      "Epoch 140/2000\n",
      "8/8 [==============================] - 0s 745us/step - loss: 68.9702\n",
      "Epoch 141/2000\n",
      "8/8 [==============================] - 0s 777us/step - loss: 68.1049\n",
      "Epoch 142/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 68.5624\n",
      "Epoch 143/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 68.2972\n",
      "Epoch 144/2000\n",
      "8/8 [==============================] - 0s 768us/step - loss: 67.4812\n",
      "Epoch 145/2000\n",
      "8/8 [==============================] - 0s 696us/step - loss: 68.0219\n",
      "Epoch 146/2000\n",
      "8/8 [==============================] - 0s 683us/step - loss: 67.7484\n",
      "Epoch 147/2000\n",
      "8/8 [==============================] - 0s 743us/step - loss: 67.4832\n",
      "Epoch 148/2000\n",
      "8/8 [==============================] - 0s 786us/step - loss: 66.8210\n",
      "Epoch 149/2000\n",
      "8/8 [==============================] - 0s 776us/step - loss: 67.0416\n",
      "Epoch 150/2000\n",
      "8/8 [==============================] - 0s 796us/step - loss: 66.2547\n",
      "Epoch 151/2000\n",
      "8/8 [==============================] - 0s 841us/step - loss: 66.6532\n",
      "Epoch 152/2000\n",
      "8/8 [==============================] - 0s 711us/step - loss: 66.3510\n",
      "Epoch 153/2000\n",
      "8/8 [==============================] - 0s 706us/step - loss: 66.4687\n",
      "Epoch 154/2000\n",
      "8/8 [==============================] - 0s 894us/step - loss: 65.7946\n",
      "Epoch 155/2000\n",
      "8/8 [==============================] - 0s 667us/step - loss: 65.3326\n",
      "Epoch 156/2000\n",
      "8/8 [==============================] - 0s 879us/step - loss: 65.3917\n",
      "Epoch 157/2000\n",
      "8/8 [==============================] - 0s 722us/step - loss: 65.2570\n",
      "Epoch 158/2000\n",
      "8/8 [==============================] - 0s 852us/step - loss: 65.4194\n",
      "Epoch 159/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 64.4554\n",
      "Epoch 160/2000\n",
      "8/8 [==============================] - 0s 718us/step - loss: 64.7804\n",
      "Epoch 161/2000\n",
      "8/8 [==============================] - 0s 770us/step - loss: 65.0769\n",
      "Epoch 162/2000\n",
      "8/8 [==============================] - 0s 892us/step - loss: 65.0185\n",
      "Epoch 163/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 64.8594\n",
      "Epoch 164/2000\n",
      "8/8 [==============================] - 0s 937us/step - loss: 64.2461\n",
      "Epoch 165/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 64.1595\n",
      "Epoch 166/2000\n",
      "8/8 [==============================] - 0s 943us/step - loss: 63.8617\n",
      "Epoch 167/2000\n",
      "8/8 [==============================] - 0s 885us/step - loss: 64.3790\n",
      "Epoch 168/2000\n",
      "8/8 [==============================] - 0s 730us/step - loss: 63.8040\n",
      "Epoch 169/2000\n",
      "8/8 [==============================] - 0s 728us/step - loss: 63.8783\n",
      "Epoch 170/2000\n",
      "8/8 [==============================] - 0s 916us/step - loss: 63.7688\n",
      "Epoch 171/2000\n",
      "8/8 [==============================] - 0s 683us/step - loss: 64.5289\n",
      "Epoch 172/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 63.7378\n",
      "Epoch 173/2000\n",
      "8/8 [==============================] - 0s 911us/step - loss: 63.4718\n",
      "Epoch 174/2000\n",
      "8/8 [==============================] - 0s 682us/step - loss: 63.3687\n",
      "Epoch 175/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 62.8284\n",
      "Epoch 176/2000\n",
      "8/8 [==============================] - 0s 883us/step - loss: 63.0271\n",
      "Epoch 177/2000\n",
      "8/8 [==============================] - 0s 745us/step - loss: 62.4127\n",
      "Epoch 178/2000\n",
      "8/8 [==============================] - 0s 774us/step - loss: 62.2967\n",
      "Epoch 179/2000\n",
      "8/8 [==============================] - 0s 660us/step - loss: 63.6163\n",
      "Epoch 180/2000\n",
      "8/8 [==============================] - 0s 692us/step - loss: 62.6239\n",
      "Epoch 181/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 62.6616\n",
      "Epoch 182/2000\n",
      "8/8 [==============================] - 0s 743us/step - loss: 62.4546\n",
      "Epoch 183/2000\n",
      "8/8 [==============================] - 0s 718us/step - loss: 62.1784\n",
      "Epoch 184/2000\n",
      "8/8 [==============================] - 0s 734us/step - loss: 62.4757\n",
      "Epoch 185/2000\n",
      "8/8 [==============================] - 0s 944us/step - loss: 61.3160\n",
      "Epoch 186/2000\n",
      "8/8 [==============================] - 0s 667us/step - loss: 62.6015\n",
      "Epoch 187/2000\n",
      "8/8 [==============================] - 0s 974us/step - loss: 61.7126\n",
      "Epoch 188/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 60.9920\n",
      "Epoch 189/2000\n",
      "8/8 [==============================] - 0s 950us/step - loss: 61.9555\n",
      "Epoch 190/2000\n",
      "8/8 [==============================] - 0s 730us/step - loss: 61.3629\n",
      "Epoch 191/2000\n",
      "8/8 [==============================] - 0s 937us/step - loss: 61.2131\n",
      "Epoch 192/2000\n",
      "8/8 [==============================] - 0s 750us/step - loss: 61.2982\n",
      "Epoch 193/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 61.0671\n",
      "Epoch 194/2000\n",
      "8/8 [==============================] - 0s 729us/step - loss: 61.2093\n",
      "Epoch 195/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 60.2404\n",
      "Epoch 196/2000\n",
      "8/8 [==============================] - 0s 641us/step - loss: 61.3772\n",
      "Epoch 197/2000\n",
      "8/8 [==============================] - 0s 705us/step - loss: 60.8340\n",
      "Epoch 198/2000\n",
      "8/8 [==============================] - 0s 742us/step - loss: 60.7007\n",
      "Epoch 199/2000\n",
      "8/8 [==============================] - 0s 701us/step - loss: 60.4588\n",
      "Epoch 200/2000\n",
      "8/8 [==============================] - 0s 968us/step - loss: 60.3737\n",
      "Epoch 201/2000\n",
      "8/8 [==============================] - 0s 776us/step - loss: 60.1663\n",
      "Epoch 202/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 60.3450\n",
      "Epoch 203/2000\n",
      "8/8 [==============================] - 0s 694us/step - loss: 59.7214\n",
      "Epoch 204/2000\n",
      "8/8 [==============================] - 0s 708us/step - loss: 59.6481\n",
      "Epoch 205/2000\n",
      "8/8 [==============================] - 0s 649us/step - loss: 59.2167\n",
      "Epoch 206/2000\n",
      "8/8 [==============================] - 0s 634us/step - loss: 59.5889\n",
      "Epoch 207/2000\n",
      "8/8 [==============================] - 0s 669us/step - loss: 59.2742\n",
      "Epoch 208/2000\n",
      "8/8 [==============================] - 0s 692us/step - loss: 59.6952\n",
      "Epoch 209/2000\n",
      "8/8 [==============================] - 0s 789us/step - loss: 59.3816\n",
      "Epoch 210/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 58.9466\n",
      "Epoch 211/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 58.9506\n",
      "Epoch 212/2000\n",
      "8/8 [==============================] - 0s 882us/step - loss: 58.6774\n",
      "Epoch 213/2000\n",
      "8/8 [==============================] - 0s 732us/step - loss: 58.3415\n",
      "Epoch 214/2000\n",
      "8/8 [==============================] - 0s 660us/step - loss: 57.2038\n",
      "Epoch 215/2000\n",
      "8/8 [==============================] - 0s 788us/step - loss: 58.2633\n",
      "Epoch 216/2000\n",
      "8/8 [==============================] - 0s 684us/step - loss: 57.9863\n",
      "Epoch 217/2000\n",
      "8/8 [==============================] - 0s 711us/step - loss: 57.7286\n",
      "Epoch 218/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 57.6355\n",
      "Epoch 219/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 57.6734\n",
      "Epoch 220/2000\n",
      "8/8 [==============================] - 0s 801us/step - loss: 57.9620\n",
      "Epoch 221/2000\n",
      "8/8 [==============================] - 0s 662us/step - loss: 58.1361\n",
      "Epoch 222/2000\n",
      "8/8 [==============================] - 0s 700us/step - loss: 57.3039\n",
      "Epoch 223/2000\n",
      "8/8 [==============================] - 0s 761us/step - loss: 56.7718\n",
      "Epoch 224/2000\n",
      "8/8 [==============================] - 0s 748us/step - loss: 57.2463\n",
      "Epoch 225/2000\n",
      "8/8 [==============================] - 0s 867us/step - loss: 57.3871\n",
      "Epoch 226/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 57.2148\n",
      "Epoch 227/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 57.3971\n",
      "Epoch 228/2000\n",
      "8/8 [==============================] - 0s 912us/step - loss: 57.2741\n",
      "Epoch 229/2000\n",
      "8/8 [==============================] - 0s 690us/step - loss: 57.1164\n",
      "Epoch 230/2000\n",
      "8/8 [==============================] - 0s 645us/step - loss: 56.4088\n",
      "Epoch 231/2000\n",
      "8/8 [==============================] - 0s 654us/step - loss: 56.8379\n",
      "Epoch 232/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 56.3068\n",
      "Epoch 233/2000\n",
      "8/8 [==============================] - 0s 903us/step - loss: 56.9830\n",
      "Epoch 234/2000\n",
      "8/8 [==============================] - 0s 688us/step - loss: 56.3714\n",
      "Epoch 235/2000\n",
      "8/8 [==============================] - 0s 861us/step - loss: 56.0203\n",
      "Epoch 236/2000\n",
      "8/8 [==============================] - 0s 643us/step - loss: 56.2073\n",
      "Epoch 237/2000\n",
      "8/8 [==============================] - 0s 761us/step - loss: 55.6319\n",
      "Epoch 238/2000\n",
      "8/8 [==============================] - 0s 744us/step - loss: 55.5620\n",
      "Epoch 239/2000\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 56.1530\n",
      "Epoch 240/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 55.3809\n",
      "Epoch 241/2000\n",
      "8/8 [==============================] - 0s 686us/step - loss: 55.1867\n",
      "Epoch 242/2000\n",
      "8/8 [==============================] - 0s 628us/step - loss: 55.3895\n",
      "Epoch 243/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 54.6459\n",
      "Epoch 244/2000\n",
      "8/8 [==============================] - 0s 641us/step - loss: 55.4003\n",
      "Epoch 245/2000\n",
      "8/8 [==============================] - 0s 688us/step - loss: 55.1084\n",
      "Epoch 246/2000\n",
      "8/8 [==============================] - 0s 853us/step - loss: 53.9982\n",
      "Epoch 247/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 55.1552\n",
      "Epoch 248/2000\n",
      "8/8 [==============================] - 0s 720us/step - loss: 55.0920\n",
      "Epoch 249/2000\n",
      "8/8 [==============================] - 0s 796us/step - loss: 54.0906\n",
      "Epoch 250/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 54.3926\n",
      "Epoch 251/2000\n",
      "8/8 [==============================] - 0s 895us/step - loss: 54.5438\n",
      "Epoch 252/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 54.1545\n",
      "Epoch 253/2000\n",
      "8/8 [==============================] - 0s 727us/step - loss: 53.5547\n",
      "Epoch 254/2000\n",
      "8/8 [==============================] - 0s 818us/step - loss: 53.1438\n",
      "Epoch 255/2000\n",
      "8/8 [==============================] - 0s 691us/step - loss: 52.9184\n",
      "Epoch 256/2000\n",
      "8/8 [==============================] - 0s 648us/step - loss: 53.7030\n",
      "Epoch 257/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 53.5681\n",
      "Epoch 258/2000\n",
      "8/8 [==============================] - 0s 679us/step - loss: 53.8646\n",
      "Epoch 259/2000\n",
      "8/8 [==============================] - 0s 660us/step - loss: 53.6394\n",
      "Epoch 260/2000\n",
      "8/8 [==============================] - 0s 756us/step - loss: 53.1335\n",
      "Epoch 261/2000\n",
      "8/8 [==============================] - 0s 717us/step - loss: 53.6816\n",
      "Epoch 262/2000\n",
      "8/8 [==============================] - 0s 694us/step - loss: 53.2993\n",
      "Epoch 263/2000\n",
      "8/8 [==============================] - 0s 905us/step - loss: 52.9026\n",
      "Epoch 264/2000\n",
      "8/8 [==============================] - 0s 657us/step - loss: 52.2214\n",
      "Epoch 265/2000\n",
      "8/8 [==============================] - 0s 666us/step - loss: 52.9613\n",
      "Epoch 266/2000\n",
      "8/8 [==============================] - 0s 758us/step - loss: 52.0383\n",
      "Epoch 267/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 52.7409\n",
      "Epoch 268/2000\n",
      "8/8 [==============================] - 0s 963us/step - loss: 52.4502\n",
      "Epoch 269/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 52.7213\n",
      "Epoch 270/2000\n",
      "8/8 [==============================] - 0s 683us/step - loss: 52.0288\n",
      "Epoch 271/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 52.4177\n",
      "Epoch 272/2000\n",
      "8/8 [==============================] - 0s 684us/step - loss: 52.0332\n",
      "Epoch 273/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 51.9344\n",
      "Epoch 274/2000\n",
      "8/8 [==============================] - 0s 633us/step - loss: 52.0336\n",
      "Epoch 275/2000\n",
      "8/8 [==============================] - 0s 665us/step - loss: 51.8029\n",
      "Epoch 276/2000\n",
      "8/8 [==============================] - 0s 865us/step - loss: 51.4482\n",
      "Epoch 277/2000\n",
      "8/8 [==============================] - 0s 661us/step - loss: 50.5657\n",
      "Epoch 278/2000\n",
      "8/8 [==============================] - 0s 678us/step - loss: 51.5717\n",
      "Epoch 279/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 51.6309\n",
      "Epoch 280/2000\n",
      "8/8 [==============================] - 0s 844us/step - loss: 51.2117\n",
      "Epoch 281/2000\n",
      "8/8 [==============================] - 0s 721us/step - loss: 50.7719\n",
      "Epoch 282/2000\n",
      "8/8 [==============================] - 0s 801us/step - loss: 50.7163\n",
      "Epoch 283/2000\n",
      "8/8 [==============================] - 0s 715us/step - loss: 50.4352\n",
      "Epoch 284/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 51.0357\n",
      "Epoch 285/2000\n",
      "8/8 [==============================] - 0s 842us/step - loss: 50.7638\n",
      "Epoch 286/2000\n",
      "8/8 [==============================] - 0s 697us/step - loss: 50.6281\n",
      "Epoch 287/2000\n",
      "8/8 [==============================] - 0s 719us/step - loss: 50.3286\n",
      "Epoch 288/2000\n",
      "8/8 [==============================] - 0s 693us/step - loss: 50.1035\n",
      "Epoch 289/2000\n",
      "8/8 [==============================] - 0s 650us/step - loss: 50.1936\n",
      "Epoch 290/2000\n",
      "8/8 [==============================] - 0s 667us/step - loss: 49.9722\n",
      "Epoch 291/2000\n",
      "8/8 [==============================] - 0s 577us/step - loss: 49.9404\n",
      "Epoch 292/2000\n",
      "8/8 [==============================] - 0s 741us/step - loss: 50.2619\n",
      "Epoch 293/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 49.7966\n",
      "Epoch 294/2000\n",
      "8/8 [==============================] - 0s 952us/step - loss: 49.7220\n",
      "Epoch 295/2000\n",
      "8/8 [==============================] - 0s 683us/step - loss: 49.4626\n",
      "Epoch 296/2000\n",
      "8/8 [==============================] - 0s 651us/step - loss: 49.6727\n",
      "Epoch 297/2000\n",
      "8/8 [==============================] - 0s 671us/step - loss: 48.7974\n",
      "Epoch 298/2000\n",
      "8/8 [==============================] - 0s 634us/step - loss: 49.6454\n",
      "Epoch 299/2000\n",
      "8/8 [==============================] - 0s 667us/step - loss: 49.2653\n",
      "Epoch 300/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 48.8478\n",
      "Epoch 301/2000\n",
      "8/8 [==============================] - 0s 568us/step - loss: 48.7019\n",
      "Epoch 302/2000\n",
      "8/8 [==============================] - 0s 559us/step - loss: 48.7741\n",
      "Epoch 303/2000\n",
      "8/8 [==============================] - 0s 765us/step - loss: 48.5145\n",
      "Epoch 304/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 48.6731\n",
      "Epoch 305/2000\n",
      "8/8 [==============================] - 0s 664us/step - loss: 48.0093\n",
      "Epoch 306/2000\n",
      "8/8 [==============================] - 0s 674us/step - loss: 48.6794\n",
      "Epoch 307/2000\n",
      "8/8 [==============================] - 0s 894us/step - loss: 48.3701\n",
      "Epoch 308/2000\n",
      "8/8 [==============================] - 0s 708us/step - loss: 48.3853\n",
      "Epoch 309/2000\n",
      "8/8 [==============================] - 0s 921us/step - loss: 48.6106\n",
      "Epoch 310/2000\n",
      "8/8 [==============================] - 0s 698us/step - loss: 48.1073\n",
      "Epoch 311/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 47.9056\n",
      "Epoch 312/2000\n",
      "8/8 [==============================] - 0s 902us/step - loss: 48.5852\n",
      "Epoch 313/2000\n",
      "8/8 [==============================] - 0s 717us/step - loss: 47.5608\n",
      "Epoch 314/2000\n",
      "8/8 [==============================] - 0s 654us/step - loss: 47.5969\n",
      "Epoch 315/2000\n",
      "8/8 [==============================] - 0s 668us/step - loss: 47.7024\n",
      "Epoch 316/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 47.1612\n",
      "Epoch 317/2000\n",
      "8/8 [==============================] - 0s 647us/step - loss: 46.7175\n",
      "Epoch 318/2000\n",
      "8/8 [==============================] - 0s 599us/step - loss: 47.4557\n",
      "Epoch 319/2000\n",
      "8/8 [==============================] - 0s 576us/step - loss: 47.2097\n",
      "Epoch 320/2000\n",
      "8/8 [==============================] - 0s 589us/step - loss: 46.9835\n",
      "Epoch 321/2000\n",
      "8/8 [==============================] - 0s 842us/step - loss: 46.7257\n",
      "Epoch 322/2000\n",
      "8/8 [==============================] - 0s 630us/step - loss: 47.1378\n",
      "Epoch 323/2000\n",
      "8/8 [==============================] - 0s 748us/step - loss: 47.0580\n",
      "Epoch 324/2000\n",
      "8/8 [==============================] - 0s 818us/step - loss: 46.8317\n",
      "Epoch 325/2000\n",
      "8/8 [==============================] - 0s 734us/step - loss: 46.5968\n",
      "Epoch 326/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 46.7766\n",
      "Epoch 327/2000\n",
      "8/8 [==============================] - 0s 717us/step - loss: 46.4401\n",
      "Epoch 328/2000\n",
      "8/8 [==============================] - 0s 742us/step - loss: 45.9279\n",
      "Epoch 329/2000\n",
      "8/8 [==============================] - 0s 929us/step - loss: 46.3541\n",
      "Epoch 330/2000\n",
      "8/8 [==============================] - 0s 674us/step - loss: 46.7068\n",
      "Epoch 331/2000\n",
      "8/8 [==============================] - 0s 665us/step - loss: 46.0171\n",
      "Epoch 332/2000\n",
      "8/8 [==============================] - 0s 659us/step - loss: 46.2361\n",
      "Epoch 333/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 45.6170\n",
      "Epoch 334/2000\n",
      "8/8 [==============================] - 0s 661us/step - loss: 45.9964\n",
      "Epoch 335/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 44.9920\n",
      "Epoch 336/2000\n",
      "8/8 [==============================] - 0s 576us/step - loss: 46.0702\n",
      "Epoch 337/2000\n",
      "8/8 [==============================] - 0s 561us/step - loss: 45.1181\n",
      "Epoch 338/2000\n",
      "8/8 [==============================] - 0s 583us/step - loss: 45.2861\n",
      "Epoch 339/2000\n",
      "8/8 [==============================] - 0s 573us/step - loss: 45.3394\n",
      "Epoch 340/2000\n",
      "8/8 [==============================] - 0s 567us/step - loss: 45.3248\n",
      "Epoch 341/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 45.0639\n",
      "Epoch 342/2000\n",
      "8/8 [==============================] - 0s 642us/step - loss: 45.0871\n",
      "Epoch 343/2000\n",
      "8/8 [==============================] - 0s 704us/step - loss: 44.2184\n",
      "Epoch 344/2000\n",
      "8/8 [==============================] - 0s 741us/step - loss: 44.8138\n",
      "Epoch 345/2000\n",
      "8/8 [==============================] - 0s 779us/step - loss: 44.8412\n",
      "Epoch 346/2000\n",
      "8/8 [==============================] - 0s 668us/step - loss: 44.6063\n",
      "Epoch 347/2000\n",
      "8/8 [==============================] - 0s 661us/step - loss: 44.6411\n",
      "Epoch 348/2000\n",
      "8/8 [==============================] - 0s 872us/step - loss: 44.4959\n",
      "Epoch 349/2000\n",
      "8/8 [==============================] - 0s 711us/step - loss: 44.1936\n",
      "Epoch 350/2000\n",
      "8/8 [==============================] - 0s 859us/step - loss: 44.0537\n",
      "Epoch 351/2000\n",
      "8/8 [==============================] - 0s 664us/step - loss: 44.1603\n",
      "Epoch 352/2000\n",
      "8/8 [==============================] - 0s 683us/step - loss: 44.1899\n",
      "Epoch 353/2000\n",
      "8/8 [==============================] - 0s 671us/step - loss: 44.2734\n",
      "Epoch 354/2000\n",
      "8/8 [==============================] - 0s 673us/step - loss: 43.1706\n",
      "Epoch 355/2000\n",
      "8/8 [==============================] - 0s 633us/step - loss: 43.8689\n",
      "Epoch 356/2000\n",
      "8/8 [==============================] - 0s 672us/step - loss: 43.8585\n",
      "Epoch 357/2000\n",
      "8/8 [==============================] - 0s 612us/step - loss: 43.9942\n",
      "Epoch 358/2000\n",
      "8/8 [==============================] - 0s 582us/step - loss: 43.5900\n",
      "Epoch 359/2000\n",
      "8/8 [==============================] - 0s 586us/step - loss: 43.3769\n",
      "Epoch 360/2000\n",
      "8/8 [==============================] - 0s 567us/step - loss: 43.6807\n",
      "Epoch 361/2000\n",
      "8/8 [==============================] - 0s 575us/step - loss: 43.1388\n",
      "Epoch 362/2000\n",
      "8/8 [==============================] - 0s 540us/step - loss: 42.7540\n",
      "Epoch 363/2000\n",
      "8/8 [==============================] - 0s 534us/step - loss: 43.3244\n",
      "Epoch 364/2000\n",
      "8/8 [==============================] - 0s 695us/step - loss: 43.2584\n",
      "Epoch 365/2000\n",
      "8/8 [==============================] - 0s 723us/step - loss: 42.5381\n",
      "Epoch 366/2000\n",
      "8/8 [==============================] - 0s 627us/step - loss: 42.5086\n",
      "Epoch 367/2000\n",
      "8/8 [==============================] - 0s 653us/step - loss: 42.5679\n",
      "Epoch 368/2000\n",
      "8/8 [==============================] - 0s 863us/step - loss: 42.0628\n",
      "Epoch 369/2000\n",
      "8/8 [==============================] - 0s 662us/step - loss: 42.5300\n",
      "Epoch 370/2000\n",
      "8/8 [==============================] - 0s 684us/step - loss: 42.2304\n",
      "Epoch 371/2000\n",
      "8/8 [==============================] - 0s 812us/step - loss: 42.6787\n",
      "Epoch 372/2000\n",
      "8/8 [==============================] - 0s 691us/step - loss: 42.0595\n",
      "Epoch 373/2000\n",
      "8/8 [==============================] - 0s 920us/step - loss: 42.5348\n",
      "Epoch 374/2000\n",
      "8/8 [==============================] - 0s 694us/step - loss: 41.3566\n",
      "Epoch 375/2000\n",
      "8/8 [==============================] - 0s 640us/step - loss: 42.2106\n",
      "Epoch 376/2000\n",
      "8/8 [==============================] - 0s 666us/step - loss: 42.1497\n",
      "Epoch 377/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 41.9390\n",
      "Epoch 378/2000\n",
      "8/8 [==============================] - 0s 656us/step - loss: 41.6647\n",
      "Epoch 379/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 41.5955\n",
      "Epoch 380/2000\n",
      "8/8 [==============================] - 0s 648us/step - loss: 41.6273\n",
      "Epoch 381/2000\n",
      "8/8 [==============================] - 0s 583us/step - loss: 41.0470\n",
      "Epoch 382/2000\n",
      "8/8 [==============================] - 0s 559us/step - loss: 41.4601\n",
      "Epoch 383/2000\n",
      "8/8 [==============================] - 0s 579us/step - loss: 41.7217\n",
      "Epoch 384/2000\n",
      "8/8 [==============================] - 0s 603us/step - loss: 41.4677\n",
      "Epoch 385/2000\n",
      "8/8 [==============================] - 0s 616us/step - loss: 41.3559\n",
      "Epoch 386/2000\n",
      "8/8 [==============================] - 0s 602us/step - loss: 41.3361\n",
      "Epoch 387/2000\n",
      "8/8 [==============================] - 0s 576us/step - loss: 41.1142\n",
      "Epoch 388/2000\n",
      "8/8 [==============================] - 0s 572us/step - loss: 40.9469\n",
      "Epoch 389/2000\n",
      "8/8 [==============================] - 0s 666us/step - loss: 40.6156\n",
      "Epoch 390/2000\n",
      "8/8 [==============================] - 0s 691us/step - loss: 40.7003\n",
      "Epoch 391/2000\n",
      "8/8 [==============================] - 0s 917us/step - loss: 40.2932\n",
      "Epoch 392/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 40.6804\n",
      "Epoch 393/2000\n",
      "8/8 [==============================] - 0s 664us/step - loss: 40.2183\n",
      "Epoch 394/2000\n",
      "8/8 [==============================] - 0s 623us/step - loss: 39.9140\n",
      "Epoch 395/2000\n",
      "8/8 [==============================] - 0s 603us/step - loss: 40.2703\n",
      "Epoch 396/2000\n",
      "8/8 [==============================] - 0s 712us/step - loss: 40.0261\n",
      "Epoch 397/2000\n",
      "8/8 [==============================] - 0s 680us/step - loss: 39.4547\n",
      "Epoch 398/2000\n",
      "8/8 [==============================] - 0s 657us/step - loss: 40.0482\n",
      "Epoch 399/2000\n",
      "8/8 [==============================] - 0s 916us/step - loss: 39.4694\n",
      "Epoch 400/2000\n",
      "8/8 [==============================] - 0s 672us/step - loss: 39.8891\n",
      "Epoch 401/2000\n",
      "8/8 [==============================] - 0s 678us/step - loss: 38.8980\n",
      "Epoch 402/2000\n",
      "8/8 [==============================] - 0s 673us/step - loss: 39.9336\n",
      "Epoch 403/2000\n",
      "8/8 [==============================] - 0s 669us/step - loss: 39.7006\n",
      "Epoch 404/2000\n",
      "8/8 [==============================] - 0s 653us/step - loss: 39.2256\n",
      "Epoch 405/2000\n",
      "8/8 [==============================] - 0s 642us/step - loss: 38.9205\n",
      "Epoch 406/2000\n",
      "8/8 [==============================] - 0s 583us/step - loss: 39.6395\n",
      "Epoch 407/2000\n",
      "8/8 [==============================] - 0s 580us/step - loss: 38.9964\n",
      "Epoch 408/2000\n",
      "8/8 [==============================] - 0s 611us/step - loss: 39.2742\n",
      "Epoch 409/2000\n",
      "8/8 [==============================] - 0s 585us/step - loss: 38.6534\n",
      "Epoch 410/2000\n",
      "8/8 [==============================] - 0s 564us/step - loss: 38.9447\n",
      "Epoch 411/2000\n",
      "8/8 [==============================] - 0s 747us/step - loss: 38.7712\n",
      "Epoch 412/2000\n",
      "8/8 [==============================] - 0s 608us/step - loss: 38.4548\n",
      "Epoch 413/2000\n",
      "8/8 [==============================] - 0s 544us/step - loss: 39.0036\n",
      "Epoch 414/2000\n",
      "8/8 [==============================] - 0s 592us/step - loss: 38.6468\n",
      "Epoch 415/2000\n",
      "8/8 [==============================] - 0s 598us/step - loss: 38.8170\n",
      "Epoch 416/2000\n",
      "8/8 [==============================] - 0s 588us/step - loss: 38.2825\n",
      "Epoch 417/2000\n",
      "8/8 [==============================] - 0s 549us/step - loss: 38.4882\n",
      "Epoch 418/2000\n",
      "8/8 [==============================] - 0s 788us/step - loss: 38.1676\n",
      "Epoch 419/2000\n",
      "8/8 [==============================] - 0s 650us/step - loss: 38.0107\n",
      "Epoch 420/2000\n",
      "8/8 [==============================] - 0s 888us/step - loss: 38.1198\n",
      "Epoch 421/2000\n",
      "8/8 [==============================] - 0s 674us/step - loss: 38.3287\n",
      "Epoch 422/2000\n",
      "8/8 [==============================] - 0s 666us/step - loss: 38.0645\n",
      "Epoch 423/2000\n",
      "8/8 [==============================] - 0s 677us/step - loss: 38.1111\n",
      "Epoch 424/2000\n",
      "8/8 [==============================] - 0s 607us/step - loss: 37.7386\n",
      "Epoch 425/2000\n",
      "8/8 [==============================] - 0s 580us/step - loss: 37.8212\n",
      "Epoch 426/2000\n",
      "8/8 [==============================] - 0s 915us/step - loss: 37.9292\n",
      "Epoch 427/2000\n",
      "8/8 [==============================] - 0s 709us/step - loss: 37.2579\n",
      "Epoch 428/2000\n",
      "8/8 [==============================] - 0s 899us/step - loss: 37.2861\n",
      "Epoch 429/2000\n",
      "8/8 [==============================] - 0s 675us/step - loss: 37.7287\n",
      "Epoch 430/2000\n",
      "8/8 [==============================] - 0s 672us/step - loss: 37.3851\n",
      "Epoch 431/2000\n",
      "8/8 [==============================] - 0s 714us/step - loss: 37.3705\n",
      "Epoch 432/2000\n",
      "8/8 [==============================] - 0s 663us/step - loss: 37.0388\n",
      "Epoch 433/2000\n",
      "8/8 [==============================] - 0s 625us/step - loss: 36.2943\n",
      "Epoch 434/2000\n",
      "8/8 [==============================] - 0s 577us/step - loss: 36.8957\n",
      "Epoch 435/2000\n",
      "8/8 [==============================] - 0s 599us/step - loss: 37.0603\n",
      "Epoch 436/2000\n",
      "8/8 [==============================] - 0s 619us/step - loss: 36.6364\n",
      "Epoch 437/2000\n",
      "8/8 [==============================] - 0s 582us/step - loss: 36.7438\n",
      "Epoch 438/2000\n",
      "8/8 [==============================] - 0s 574us/step - loss: 36.1099\n",
      "Epoch 439/2000\n",
      "8/8 [==============================] - 0s 570us/step - loss: 36.5554\n",
      "Epoch 440/2000\n",
      "8/8 [==============================] - 0s 623us/step - loss: 36.4534\n",
      "Epoch 441/2000\n",
      "8/8 [==============================] - 0s 596us/step - loss: 36.5357\n",
      "Epoch 442/2000\n",
      "8/8 [==============================] - 0s 571us/step - loss: 36.2829\n",
      "Epoch 443/2000\n",
      "8/8 [==============================] - 0s 582us/step - loss: 35.8740\n",
      "Epoch 444/2000\n",
      "8/8 [==============================] - 0s 535us/step - loss: 36.1804\n",
      "Epoch 445/2000\n",
      "8/8 [==============================] - 0s 571us/step - loss: 36.0479\n",
      "Epoch 446/2000\n",
      "8/8 [==============================] - 0s 568us/step - loss: 35.3934\n",
      "Epoch 447/2000\n",
      "8/8 [==============================] - 0s 546us/step - loss: 35.7307\n",
      "Epoch 448/2000\n",
      "8/8 [==============================] - 0s 564us/step - loss: 35.7874\n",
      "Epoch 449/2000\n",
      "8/8 [==============================] - 0s 564us/step - loss: 36.0376\n",
      "Epoch 450/2000\n",
      "8/8 [==============================] - 0s 572us/step - loss: 35.8822\n",
      "Epoch 451/2000\n",
      "8/8 [==============================] - 0s 614us/step - loss: 35.0905\n",
      "Epoch 452/2000\n",
      "8/8 [==============================] - 0s 762us/step - loss: 35.4420\n",
      "Epoch 453/2000\n",
      "8/8 [==============================] - 0s 659us/step - loss: 35.5400\n",
      "Epoch 454/2000\n",
      "8/8 [==============================] - 0s 682us/step - loss: 35.4410\n",
      "Epoch 455/2000\n",
      "8/8 [==============================] - 0s 694us/step - loss: 35.5310\n",
      "Epoch 456/2000\n",
      "8/8 [==============================] - 0s 791us/step - loss: 34.9310\n",
      "Epoch 457/2000\n",
      "8/8 [==============================] - 0s 637us/step - loss: 35.0475\n",
      "Epoch 458/2000\n",
      "8/8 [==============================] - 0s 711us/step - loss: 34.9446\n",
      "Epoch 459/2000\n",
      "8/8 [==============================] - 0s 702us/step - loss: 35.1269\n",
      "Epoch 460/2000\n",
      "8/8 [==============================] - 0s 789us/step - loss: 34.4991\n",
      "Epoch 461/2000\n",
      "8/8 [==============================] - 0s 657us/step - loss: 34.3913\n",
      "Epoch 462/2000\n",
      "8/8 [==============================] - 0s 664us/step - loss: 34.3083\n",
      "Epoch 463/2000\n",
      "8/8 [==============================] - 0s 907us/step - loss: 34.1474\n",
      "Epoch 464/2000\n",
      "8/8 [==============================] - 0s 641us/step - loss: 34.0539\n",
      "Epoch 465/2000\n",
      "8/8 [==============================] - 0s 652us/step - loss: 34.4362\n",
      "Epoch 466/2000\n",
      "8/8 [==============================] - 0s 673us/step - loss: 34.2767\n",
      "Epoch 467/2000\n",
      "8/8 [==============================] - 0s 659us/step - loss: 34.5007\n",
      "Epoch 468/2000\n",
      "8/8 [==============================] - 0s 649us/step - loss: 33.5242\n",
      "Epoch 469/2000\n",
      "8/8 [==============================] - 0s 567us/step - loss: 34.0302\n",
      "Epoch 470/2000\n",
      "8/8 [==============================] - 0s 607us/step - loss: 33.9732\n",
      "Epoch 471/2000\n",
      "8/8 [==============================] - 0s 565us/step - loss: 33.3510\n",
      "Epoch 472/2000\n",
      "8/8 [==============================] - 0s 547us/step - loss: 33.3994\n",
      "Epoch 473/2000\n",
      "8/8 [==============================] - 0s 587us/step - loss: 33.7646\n",
      "Epoch 474/2000\n",
      "8/8 [==============================] - 0s 578us/step - loss: 33.8234\n",
      "Epoch 475/2000\n",
      "8/8 [==============================] - 0s 568us/step - loss: 33.3541\n",
      "Epoch 476/2000\n",
      "8/8 [==============================] - 0s 585us/step - loss: 33.6431\n",
      "Epoch 477/2000\n",
      "8/8 [==============================] - 0s 578us/step - loss: 33.3376\n",
      "Epoch 478/2000\n",
      "8/8 [==============================] - 0s 562us/step - loss: 33.7425\n",
      "Epoch 479/2000\n",
      "8/8 [==============================] - 0s 579us/step - loss: 33.5045\n",
      "Epoch 480/2000\n",
      "8/8 [==============================] - 0s 613us/step - loss: 32.7536\n",
      "Epoch 481/2000\n",
      "8/8 [==============================] - 0s 676us/step - loss: 32.5063\n",
      "Epoch 482/2000\n",
      "8/8 [==============================] - 0s 566us/step - loss: 33.3102\n",
      "Epoch 483/2000\n",
      "8/8 [==============================] - 0s 600us/step - loss: 32.1455\n",
      "Epoch 484/2000\n",
      "8/8 [==============================] - 0s 578us/step - loss: 33.0306\n",
      "Epoch 485/2000\n",
      "8/8 [==============================] - 0s 574us/step - loss: 32.3514\n",
      "Epoch 486/2000\n",
      "8/8 [==============================] - 0s 570us/step - loss: 32.4226\n",
      "Epoch 487/2000\n",
      "8/8 [==============================] - 0s 566us/step - loss: 32.7069\n",
      "Epoch 488/2000\n",
      "8/8 [==============================] - 0s 571us/step - loss: 32.6524\n",
      "Epoch 489/2000\n",
      "8/8 [==============================] - 0s 637us/step - loss: 32.1496\n",
      "Epoch 490/2000\n",
      "8/8 [==============================] - 0s 745us/step - loss: 32.2643\n",
      "Epoch 491/2000\n",
      "8/8 [==============================] - 0s 664us/step - loss: 32.3144\n",
      "Epoch 492/2000\n",
      "8/8 [==============================] - 0s 707us/step - loss: 32.3400\n",
      "Epoch 493/2000\n",
      "8/8 [==============================] - 0s 913us/step - loss: 31.8739\n",
      "Epoch 494/2000\n",
      "8/8 [==============================] - 0s 654us/step - loss: 32.1516\n",
      "Epoch 495/2000\n",
      "8/8 [==============================] - 0s 725us/step - loss: 31.5516\n",
      "Epoch 496/2000\n",
      "8/8 [==============================] - 0s 603us/step - loss: 31.9355\n",
      "Epoch 497/2000\n",
      "8/8 [==============================] - 0s 572us/step - loss: 32.1154\n",
      "Epoch 498/2000\n",
      "8/8 [==============================] - 0s 939us/step - loss: 31.6586\n",
      "Epoch 499/2000\n",
      "8/8 [==============================] - 0s 690us/step - loss: 31.6479\n",
      "Epoch 500/2000\n",
      "8/8 [==============================] - 0s 669us/step - loss: 30.7211\n",
      "Epoch 501/2000\n",
      "8/8 [==============================] - 0s 828us/step - loss: 31.2812\n",
      "Epoch 502/2000\n",
      "8/8 [==============================] - 0s 696us/step - loss: 31.1583\n",
      "Epoch 503/2000\n",
      "8/8 [==============================] - 0s 681us/step - loss: 31.4788\n",
      "Epoch 504/2000\n",
      "8/8 [==============================] - 0s 676us/step - loss: 31.0341\n",
      "Epoch 505/2000\n",
      "8/8 [==============================] - 0s 658us/step - loss: 31.0355\n",
      "Epoch 506/2000\n",
      "8/8 [==============================] - 0s 654us/step - loss: 30.7856\n",
      "Epoch 507/2000\n",
      "8/8 [==============================] - 0s 605us/step - loss: 30.8024\n",
      "Epoch 508/2000\n",
      "8/8 [==============================] - 0s 571us/step - loss: 30.7335\n",
      "Epoch 509/2000\n",
      "8/8 [==============================] - 0s 578us/step - loss: 30.8953\n",
      "Epoch 510/2000\n",
      "8/8 [==============================] - 0s 599us/step - loss: 30.8587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff39cd9fca0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "stopper = EarlyStopping(monitor=\"loss\", patience=10, restore_best_weights=True)\n",
    "model.fit([df2.drop('Sen2.5', axis=1).drop([\"Raster.Cell\", \"x\", \"y\"], axis=1), df2['Sen2.5'], ipw_weights], epochs=2000, batch_size=200, callbacks=[stopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this model copies weights and removes the other 2 inputs for easier use\n",
    "# as shown below, this does not appear to actually work??\n",
    "pred_model = Model(inputs=mlp, outputs=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2389.9194  ],\n",
       "       [2389.7512  ],\n",
       "       [2389.8975  ],\n",
       "       ...,\n",
       "       [  98.87438 ],\n",
       "       [  98.93127 ],\n",
       "       [  99.875916]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model.predict(df2.drop('Sen2.5', axis=1).drop([\"Raster.Cell\", \"x\", \"y\"], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.507674],\n",
       "       [12.085395],\n",
       "       [10.660815],\n",
       "       ...,\n",
       "       [ 9.463694],\n",
       "       [12.019959],\n",
       "       [10.612422]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([df2.drop('Sen2.5', axis=1).drop([\"Raster.Cell\", \"x\", \"y\"], axis=1), df2['Sen2.5'], ipw_weights])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test set 0  is 4.97306749010275\n",
      "r2 for test set 0  is 0.44555728404877404\n",
      "MSE for test set 1  is 6.719892444654097\n",
      "r2 for test set 1  is 0.4204209414719755\n",
      "MSE for test set 2  is 18.473919086310914\n",
      "r2 for test set 2  is 0.21748450141151243\n",
      "MSE for test set 3  is 6.953672565375391\n",
      "r2 for test set 3  is 0.37752298498041137\n",
      "MSE for test set 4  is 3.1921411571914615\n",
      "r2 for test set 4  is 0.3747639556506792\n",
      "MSE for test set 5  is 3.1377784409639458\n",
      "r2 for test set 5  is 0.41296982295697404\n",
      "MSE for test set 6  is 3.2579540564146687\n",
      "r2 for test set 6  is 0.3595505906255253\n",
      "MSE for test set 7  is 3.8944088601121685\n",
      "r2 for test set 7  is 0.24748725774273883\n",
      "MSE for test set 8  is 4.219436028704856\n",
      "r2 for test set 8  is 0.3554339863526096\n",
      "MSE for test set 9  is 3.238709277780715\n",
      "r2 for test set 9  is 0.4165866925696836\n",
      "test estimate MSE k-fold= 5.806097940761097 test estimate MSE standard err= 4.433157477549257\n",
      "test estimate r2 k-fold= 0.36277780178108837 test estimate r2 standard err= 0.07100513887145664\n",
      "train set r2 k-fold= 0.3725304808481718 train set r2 standard err= 0.016458998431312176\n"
     ]
    }
   ],
   "source": [
    "#Train the neural network model\n",
    "# random CV\n",
    "Xvars = df2.drop('Sen2.5', axis=1).drop([\"Raster.Cell\", \"x\", \"y\"], axis=1)\n",
    "yvars = df2['Sen2.5']\n",
    "weights = pd.Series(ipw_weights)\n",
    "weights.index = Xvars.index\n",
    "model_weights = []\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=10, shuffle=True)\n",
    "\n",
    "MSE_vec_kf = np.zeros(10)\n",
    "r2_vec_kf_train =  np.zeros(10)\n",
    "r2_vec_kf = np.zeros(10)\n",
    "\n",
    "k_ind = int(0)\n",
    "for train_index, test_index in kf.split(Xvars):\n",
    "    X_train, X_test = Xvars.loc[train_index], Xvars.loc[test_index]\n",
    "    y_train, y_test = yvars.loc[train_index], yvars.loc[test_index]\n",
    "    w_train, w_test = weights.loc[train_index], weights.loc[test_index]\n",
    "\n",
    "    # Standarize the input variables\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # split again for validation data\n",
    "    X_t, X_val, y_t, y_val, w_t, w_val = train_test_split(X_train, y_train, w_train)\n",
    "    \n",
    "    stopper = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    mlp = get_model()\n",
    "    # TODO: need to work this; stopper is too greedy/training too volatile\n",
    "    # TODO: also consider transform, inverse-transform for y vars\n",
    "    mlp.fit([X_t, y_t, w_t], validation_data=[X_val, y_val, w_val], epochs=2000, batch_size=200, callbacks=[stopper], verbose=0)\n",
    "    y_pred_train = mlp.predict([X_train, y_train, w_train])\n",
    "    y_pred = mlp.predict([X_test, y_test, w_test]).reshape(len(test_index))\n",
    "    r2_vec_kf_train[k_ind] =  r2_score(y_train, y_pred_train)\n",
    "    r2_vec_kf[k_ind] = r2_score(y_test, y_pred)\n",
    "    MSE_vec_kf[k_ind] = ((y_test - y_pred) ** 2).mean()\n",
    "    print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    print('r2 for test set', k_ind, ' is', r2_vec_kf[k_ind])\n",
    "    k_ind += 1\n",
    "    model_weights.append(mlp.get_weights())\n",
    "\n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print('test estimate MSE k-fold=', MSE_kf,\n",
    "      'test estimate MSE standard err=', MSE_kf_std)\n",
    "\n",
    "r2_kf =r2_vec_kf.mean()\n",
    "r2_kf_std = r2_vec_kf.std()\n",
    "print('test estimate r2 k-fold=', r2_kf,\n",
    "      'test estimate r2 standard err=', r2_kf_std)\n",
    "\n",
    "r2_kf_train =r2_vec_kf_train.mean()\n",
    "r2_kf_std_train = r2_vec_kf_train.std()\n",
    "print('train set r2 k-fold=', r2_kf_train,\n",
    "      'train set r2 standard err=', r2_kf_std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the weights of the 10 models\n",
    "mean_weights = [np.full(model_weights[0][0].shape, 0.0), np.full(model_weights[0][1].shape, 0.0)]\n",
    "for weight in model_weights:\n",
    "    for i in range(len(weight)):\n",
    "        mean_weights[i] += weight[i] / len(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean = get_model()\n",
    "model_mean.set_weights(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37672402177127207\n",
      "5.549890946624801\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_mean.predict([scaler.transform(Xvars), yvars, weights]).reshape(len(yvars))\n",
    "y_test = yvars\n",
    "print(r2_score(y_test, y_pred))\n",
    "print(((y_test - y_pred) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>5.549890946624801</td>\n",
       "      <td>4.433157477549257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.37672402177127207</td>\n",
       "      <td>0.07100513887145664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statistic                 mean                   sd\n",
       "0       MSE    5.549890946624801    4.433157477549257\n",
       "1        R2  0.37672402177127207  0.07100513887145664"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame(np.array([\"MSE\", ((y_test - y_pred) ** 2).mean(), MSE_kf_std, \"R2\", r2_score(y_test, y_pred), r2_kf_std]).reshape(2, 3),\\\n",
    "            columns=[\"statistic\", \"mean\", \"sd\"])\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(\"../../Downloads/nn_outlier_stats_ipw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial CV version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kMeansVars = df2.drop('Sen2.5', axis=1)\n",
    "Xvars = df2.drop('Sen2.5', axis=1).drop([\"Raster.Cell\", \"x\", \"y\"], axis=1)\n",
    "yvars = df2['Sen2.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(10).fit(np.array(kMeansVars[[\"x\", \"y\"]]).reshape(-1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "1 16743\n",
      "6\n",
      "1 4557\n",
      "3\n",
      "5\n",
      "1 35637\n",
      "1 46895\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# check fold sizes\n",
    "fold_sizes = np.zeros(10)\n",
    "for fold in np.unique(kmeans.labels_):\n",
    "    fold_sizes[fold] = len(np.unique(df2[kmeans.labels_ == fold][\"Raster.Cell\"]))\n",
    "    if (len(np.unique(df2[kmeans.labels_ == fold][\"Raster.Cell\"])) == 1):\n",
    "        print(len(np.unique(df2[kmeans.labels_ == fold][\"Raster.Cell\"])), df2[kmeans.labels_ == fold][\"Raster.Cell\"].iloc[0])\n",
    "        continue\n",
    "    print(len(np.unique(df2[kmeans.labels_ == fold][\"Raster.Cell\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for test set 0  is 7.2280016030554055\n",
      "r2 for test set 0  is -0.3047400291194615\n",
      "MSE for test set 1  is 2.0205824601539257\n",
      "r2 for test set 1  is 0.4602967908121287\n",
      "MSE for test set 2  is 4.855087012000389\n",
      "r2 for test set 2  is 0.15528351697640796\n",
      "MSE for test set 3  is 4.9928763361146355\n",
      "r2 for test set 3  is -0.1732171682799104\n",
      "MSE for test set 4  is 2.6741662972756965\n",
      "r2 for test set 4  is 0.3873175491213702\n",
      "MSE for test set 5  is 2.701626809709115\n",
      "r2 for test set 5  is 0.3800076999049452\n",
      "MSE for test set 6  is 1.9144212973830554\n",
      "r2 for test set 6  is 0.46122937513707374\n",
      "MSE for test set 7  is 3.8924698342915405\n",
      "r2 for test set 7  is -0.058392437697892374\n",
      "MSE for test set 8  is 3.211952716515134\n",
      "r2 for test set 8  is 0.4776645911028863\n",
      "MSE for test set 9  is 6.179079172750569\n",
      "r2 for test set 9  is -0.4454307635823993\n",
      "test estimate MSE k-fold= 4.763929371524811 test estimate MSE standard err= 1.8731259658433548\n",
      "test estimate r2 k-fold= 0.04435295948872399 test estimate r2 standard err= 0.34025332555875754\n",
      "train set r2 k-fold= 0.34015709111382386 train set r2 standard err= 0.0941873054483267\n"
     ]
    }
   ],
   "source": [
    "#Train the neural network model\n",
    "\n",
    "MSE_vec_kf = np.zeros(len(np.unique(df2[\"Raster.Cell\"])))\n",
    "r2_vec_kf_train =  np.zeros(len(np.unique(df2[\"Raster.Cell\"])))\n",
    "r2_vec_kf = np.zeros(len(np.unique(df2[\"Raster.Cell\"])))\n",
    "\n",
    "k_ind = int(0)\n",
    "for fold in np.unique(kmeans.labels_):\n",
    "    X_train, X_test = Xvars.loc[kmeans.labels_ != fold], Xvars.loc[kmeans.labels_ == fold]\n",
    "    y_train, y_test = yvars.loc[kmeans.labels_ != fold], yvars.loc[kmeans.labels_ == fold]\n",
    "    w_train, w_test = weights.loc[kmeans.labels_ != fold], weights.loc[kmeans.labels_ == fold]\n",
    "\n",
    "    # Standarize the input variables\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # split again for validation data\n",
    "    X_t, X_val, y_t, y_val, w_t, w_val = train_test_split(X_train, y_train, w_train)\n",
    "    \n",
    "    stopper = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "    mlp = get_model()\n",
    "    # TODO: need to work this; stopper is too greedy/training too volatile\n",
    "    # TODO: also consider transform, inverse-transform for y vars\n",
    "    mlp.fit([X_t, y_t, w_t], validation_data=[X_val, y_val, w_val], epochs=2000, batch_size=200, callbacks=[stopper], verbose=0)\n",
    "    y_pred_train = mlp.predict([X_train, y_train, w_train])\n",
    "    y_pred = mlp.predict([X_test, y_test, w_test]).reshape((kmeans.labels_ == fold).sum())\n",
    "    r2_train =  r2_score(y_train, y_pred_train)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    MSE = ((y_test - y_pred) ** 2).mean()\n",
    "    print('MSE for test set', fold, ' is', MSE)\n",
    "    print('r2 for test set', fold, ' is', r2)\n",
    "    \n",
    "    # repeats the test statistic values to weight by fold size\n",
    "    for idx in range(int(fold_sizes[fold])):\n",
    "        MSE_vec_kf[idx + k_ind] = MSE\n",
    "        r2_vec_kf[idx + k_ind] = r2\n",
    "        r2_vec_kf_train[idx + k_ind] = r2_train\n",
    "    \n",
    "    k_ind += int(fold_sizes[fold])\n",
    "    \n",
    "MSE_kf = MSE_vec_kf.mean()\n",
    "MSE_kf_std = MSE_vec_kf.std()\n",
    "print('test estimate MSE k-fold=', MSE_kf,\n",
    "      'test estimate MSE standard err=', MSE_kf_std)\n",
    "\n",
    "r2_kf =r2_vec_kf.mean()\n",
    "r2_kf_std = r2_vec_kf.std()\n",
    "print('test estimate r2 k-fold=', r2_kf,\n",
    "      'test estimate r2 standard err=', r2_kf_std)\n",
    "\n",
    "r2_kf_train =r2_vec_kf_train.mean()\n",
    "r2_kf_std_train = r2_vec_kf_train.std()\n",
    "print('train set r2 k-fold=', r2_kf_train,\n",
    "      'train set r2 standard err=', r2_kf_std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average the weights of the 10 models\n",
    "mean_weights = [np.full(model_weights[0][0].shape, 0.0), np.full(model_weights[0][1].shape, 0.0)]\n",
    "for weight in model_weights:\n",
    "    for i in range(len(weight)):\n",
    "        mean_weights[i] += weight[i] / len(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean = get_model()\n",
    "model_mean.set_weights(mean_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45900755157054074\n",
      "2.8947936433060732\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_mean.predict([scaler.transform(Xvars), yvars, weights]).reshape(len(yvars))\n",
    "y_test = yvars\n",
    "print(r2_score(y_test, y_pred))\n",
    "print(((y_test - y_pred) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statistic</th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSE</td>\n",
       "      <td>2.8947936433060732</td>\n",
       "      <td>1.8731259658433548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.45900755157054074</td>\n",
       "      <td>0.34025332555875754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  statistic                 mean                   sd\n",
       "0       MSE   2.8947936433060732   1.8731259658433548\n",
       "1        R2  0.45900755157054074  0.34025332555875754"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = pd.DataFrame(np.array([\"MSE\", ((y_test - y_pred) ** 2).mean(), MSE_kf_std, \"R2\", r2_score(y_test, y_pred), r2_kf_std]).reshape(2, 3),\\\n",
    "            columns=[\"statistic\", \"mean\", \"sd\"])\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.to_csv(\"nn_spatialcv_stats_ipw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raster.Cell</th>\n",
       "      <th>Sen2.5</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>AOD</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Elev</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Vsby</th>\n",
       "      <th>WdVl</th>\n",
       "      <th>...</th>\n",
       "      <th>LC_LowDev</th>\n",
       "      <th>LC_HighDev</th>\n",
       "      <th>PS</th>\n",
       "      <th>relh</th>\n",
       "      <th>Popd</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>610</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1652</td>\n",
       "      <td>42.3448</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1014.2213</td>\n",
       "      <td>8.9448</td>\n",
       "      <td>8.2791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.2791</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>68.6514</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.5280</td>\n",
       "      <td>43.1902</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>610</td>\n",
       "      <td>nan</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>55.0620</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.4208</td>\n",
       "      <td>9.2196</td>\n",
       "      <td>6.6575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.6575</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>70.3450</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.5280</td>\n",
       "      <td>43.1902</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>610</td>\n",
       "      <td>nan</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>63.9627</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1013.5480</td>\n",
       "      <td>7.6623</td>\n",
       "      <td>6.0854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0854</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>76.1868</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.5280</td>\n",
       "      <td>43.1902</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>610</td>\n",
       "      <td>nan</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>65.6833</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.3088</td>\n",
       "      <td>9.5372</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>72.9863</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.5280</td>\n",
       "      <td>43.1902</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>nan</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>0.2284</td>\n",
       "      <td>67.5053</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.6050</td>\n",
       "      <td>8.5467</td>\n",
       "      <td>4.4955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.4955</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>80.3597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.5280</td>\n",
       "      <td>43.1902</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raster.Cell  Sen2.5  month  year    AOD    Temp     Elev      MSLP   Vsby  \\\n",
       "0          610     nan      4    14 0.1652 42.3448 266.5581 1014.2213 8.9448   \n",
       "1          610     nan      5    14 0.1203 55.0620 266.5581 1015.4208 9.2196   \n",
       "2          610     nan      6    14 0.1341 63.9627 266.5581 1013.5480 7.6623   \n",
       "3          610     nan      7    14 0.4217 65.6833 266.5581 1015.3088 9.5372   \n",
       "4          610     nan      8    14 0.2284 67.5053 266.5581 1015.6050 8.5467   \n",
       "\n",
       "    WdVl  ...  LC_LowDev  LC_HighDev      PS    relh   Popd        x       y  \\\n",
       "0 8.2791  ...     0.0000      8.2791 10.5829 68.6514 0.0000 -88.5280 43.1902   \n",
       "1 6.6575  ...     0.0000      6.6575 10.5829 70.3450 0.0000 -88.5280 43.1902   \n",
       "2 6.0854  ...     0.0000      6.0854 10.5829 76.1868 0.0000 -88.5280 43.1902   \n",
       "3 5.7522  ...     0.0000      5.7522 10.5829 72.9863 0.0000 -88.5280 43.1902   \n",
       "4 4.4955  ...     0.0000      4.4955 10.5829 80.3597 0.0000 -88.5280 43.1902   \n",
       "\n",
       "   primary  secondary  motorway  \n",
       "0   0.0000     0.0000    0.0000  \n",
       "1   0.0000     0.0000    0.0000  \n",
       "2   0.0000     0.0000    0.0000  \n",
       "3   0.0000     0.0000    0.0000  \n",
       "4   0.0000     0.0000    0.0000  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the second stage data\n",
    "# df_second = pd.read_csv(\"NN_second_stage.csv\")\n",
    "df_second = pd.read_csv(\"../../Downloads/second_stage_20210601.csv\")\n",
    "df_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1536690, 21)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the cells vith NA values\n",
    "df_second=df_second[(~df_second['NDVI'].isna())& (~df_second['Popd'].isna())]\n",
    "df_second = df_second.drop(\"Sen2.5\", axis=1)\n",
    "df_second.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09792518, 1.01922982, 1.0062817 , ..., 1.03234357, 1.36567035,\n",
       "       1.50930033])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate IPW weights for 2nd stage\n",
    "ipw_weights_2 = 1 / ipw_model.predict_proba(df_second[[\"Elev\", \"Temp\", \"MSLP\", \"month\"]])[:, 1]\n",
    "ipw_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = df_second[[\"Raster.Cell\",\"month\",\"year\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOD</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Elev</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Vsby</th>\n",
       "      <th>WdVl</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>LC_MedDev</th>\n",
       "      <th>LC_LowDev</th>\n",
       "      <th>LC_HighDev</th>\n",
       "      <th>PS</th>\n",
       "      <th>relh</th>\n",
       "      <th>Popd</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "      <td>1536690.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.1663</td>\n",
       "      <td>53.8314</td>\n",
       "      <td>221.2532</td>\n",
       "      <td>1016.7156</td>\n",
       "      <td>8.8666</td>\n",
       "      <td>6.7942</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>6.7942</td>\n",
       "      <td>12.1723</td>\n",
       "      <td>73.3439</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-87.8070</td>\n",
       "      <td>41.7993</td>\n",
       "      <td>723.4965</td>\n",
       "      <td>884.6209</td>\n",
       "      <td>599.1359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0938</td>\n",
       "      <td>15.3615</td>\n",
       "      <td>32.0532</td>\n",
       "      <td>2.6933</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>1.4628</td>\n",
       "      <td>0.2027</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>1.4628</td>\n",
       "      <td>8.5076</td>\n",
       "      <td>5.5602</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.5991</td>\n",
       "      <td>0.6392</td>\n",
       "      <td>1576.0544</td>\n",
       "      <td>1773.8034</td>\n",
       "      <td>2240.8581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>20.9046</td>\n",
       "      <td>149.3274</td>\n",
       "      <td>1011.2849</td>\n",
       "      <td>6.5153</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>-0.1403</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.9493</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>38.7312</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.7758</td>\n",
       "      <td>40.7412</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.1027</td>\n",
       "      <td>39.6843</td>\n",
       "      <td>199.5573</td>\n",
       "      <td>1014.7415</td>\n",
       "      <td>8.5675</td>\n",
       "      <td>5.6362</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.6362</td>\n",
       "      <td>8.9648</td>\n",
       "      <td>69.7168</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-88.2802</td>\n",
       "      <td>41.2827</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.1425</td>\n",
       "      <td>56.1608</td>\n",
       "      <td>213.3082</td>\n",
       "      <td>1016.3637</td>\n",
       "      <td>8.9549</td>\n",
       "      <td>6.8828</td>\n",
       "      <td>0.4623</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.8828</td>\n",
       "      <td>11.2097</td>\n",
       "      <td>74.0631</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-87.9498</td>\n",
       "      <td>41.6325</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.2056</td>\n",
       "      <td>68.3399</td>\n",
       "      <td>239.6572</td>\n",
       "      <td>1018.6949</td>\n",
       "      <td>9.2581</td>\n",
       "      <td>7.8992</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>7.8992</td>\n",
       "      <td>13.1616</td>\n",
       "      <td>77.1286</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>-87.3598</td>\n",
       "      <td>42.3156</td>\n",
       "      <td>475.0318</td>\n",
       "      <td>1007.5490</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.7891</td>\n",
       "      <td>75.3651</td>\n",
       "      <td>351.6488</td>\n",
       "      <td>1023.1313</td>\n",
       "      <td>9.8292</td>\n",
       "      <td>10.5263</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>10.5263</td>\n",
       "      <td>382.0000</td>\n",
       "      <td>93.1307</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>-86.4748</td>\n",
       "      <td>43.1902</td>\n",
       "      <td>18537.3689</td>\n",
       "      <td>23797.0901</td>\n",
       "      <td>40774.7948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AOD         Temp         Elev         MSLP         Vsby  \\\n",
       "count 1536690.0000 1536690.0000 1536690.0000 1536690.0000 1536690.0000   \n",
       "mean        0.1663      53.8314     221.2532    1016.7156       8.8666   \n",
       "std         0.0938      15.3615      32.0532       2.6933       0.5477   \n",
       "min         0.0000      20.9046     149.3274    1011.2849       6.5153   \n",
       "25%         0.1027      39.6843     199.5573    1014.7415       8.5675   \n",
       "50%         0.1425      56.1608     213.3082    1016.3637       8.9549   \n",
       "75%         0.2056      68.3399     239.6572    1018.6949       9.2581   \n",
       "max         1.7891      75.3651     351.6488    1023.1313       9.8292   \n",
       "\n",
       "              WdVl         NDVI    LC_MedDev    LC_LowDev   LC_HighDev  \\\n",
       "count 1536690.0000 1536690.0000 1536690.0000 1536690.0000 1536690.0000   \n",
       "mean        6.7942       0.4902       0.0953       0.0407       6.7942   \n",
       "std         1.4628       0.2027       0.1378       0.0805       1.4628   \n",
       "min         2.9493      -0.1403       0.0000       0.0000       2.9493   \n",
       "25%         5.6362       0.3217       0.0020       0.0000       5.6362   \n",
       "50%         6.8828       0.4623       0.0210       0.0000       6.8828   \n",
       "75%         7.8992       0.6532       0.1490       0.0390       7.8992   \n",
       "max        10.5263       0.9456       0.8350       0.5600      10.5263   \n",
       "\n",
       "                PS         relh         Popd            x            y  \\\n",
       "count 1536690.0000 1536690.0000 1536690.0000 1536690.0000 1536690.0000   \n",
       "mean       12.1723      73.3439       0.0005     -87.8070      41.7993   \n",
       "std         8.5076       5.5602       0.0012       0.5991       0.6392   \n",
       "min         1.0000      38.7312       0.0000     -88.7758      40.7412   \n",
       "25%         8.9648      69.7168       0.0000     -88.2802      41.2827   \n",
       "50%        11.2097      74.0631       0.0001     -87.9498      41.6325   \n",
       "75%        13.1616      77.1286       0.0004     -87.3598      42.3156   \n",
       "max       382.0000      93.1307       0.0333     -86.4748      43.1902   \n",
       "\n",
       "           primary    secondary     motorway  \n",
       "count 1536690.0000 1536690.0000 1536690.0000  \n",
       "mean      723.4965     884.6209     599.1359  \n",
       "std      1576.0544    1773.8034    2240.8581  \n",
       "min         0.0000       0.0000       0.0000  \n",
       "25%         0.0000       0.0000       0.0000  \n",
       "50%         0.0000       0.0000       0.0000  \n",
       "75%       475.0318    1007.5490       0.0000  \n",
       "max     18537.3689   23797.0901   40774.7948  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = \"{:.4f}\".format\n",
    "df_second.drop([\"Raster.Cell\",\"month\",\"year\"], axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_second\n",
    "df_2['month_str']=df_2[[\"month\"]].astype(str)\n",
    "df_2['year_str'] =df_2[[\"year\"]].astype(str)\n",
    "df_2['time_str']= df_2['year_str']+'-'+df_2['month_str']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.join(pd.get_dummies(df_2['month'],drop_first=True)).join(pd.get_dummies(df_2['year'],drop_first=True))\n",
    "df_2 = df_2.drop(['month_str','year_str','time_str'], axis=1)\n",
    "df_2 = df_2.drop([\"month\",\"year\",\"Raster.Cell\",\"x\",\"y\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate empty predictions (needed for structure)\n",
    "y_2 = np.empty(df_2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model got from stage one to get the predictions\n",
    "data = scaler.transform(df_2)\n",
    "data_pred = model_mean.predict([data, y_2, ipw_weights_2])\n",
    "df_2['pred'] = data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.join(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOD</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Elev</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Vsby</th>\n",
       "      <th>WdVl</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>LC_MedDev</th>\n",
       "      <th>LC_LowDev</th>\n",
       "      <th>LC_HighDev</th>\n",
       "      <th>PS</th>\n",
       "      <th>relh</th>\n",
       "      <th>Popd</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway</th>\n",
       "      <th>pred</th>\n",
       "      <th>Raster.Cell</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1652</td>\n",
       "      <td>42.3448</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1014.2213</td>\n",
       "      <td>8.9448</td>\n",
       "      <td>8.2791</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.2791</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>68.6514</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.9458</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1203</td>\n",
       "      <td>55.0620</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.4208</td>\n",
       "      <td>9.2196</td>\n",
       "      <td>6.6575</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.6575</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>70.3450</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.3105</td>\n",
       "      <td>610</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1341</td>\n",
       "      <td>63.9627</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1013.5480</td>\n",
       "      <td>7.6623</td>\n",
       "      <td>6.0854</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0854</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>76.1868</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.9541</td>\n",
       "      <td>610</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4217</td>\n",
       "      <td>65.6833</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.3088</td>\n",
       "      <td>9.5372</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>72.9863</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.7878</td>\n",
       "      <td>610</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2284</td>\n",
       "      <td>67.5053</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.6050</td>\n",
       "      <td>8.5467</td>\n",
       "      <td>4.4955</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.4955</td>\n",
       "      <td>10.5829</td>\n",
       "      <td>80.3597</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.8360</td>\n",
       "      <td>610</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AOD    Temp     Elev      MSLP   Vsby   WdVl   NDVI  LC_MedDev  \\\n",
       "0 0.1652 42.3448 266.5581 1014.2213 8.9448 8.2791 0.2914     0.0000   \n",
       "1 0.1203 55.0620 266.5581 1015.4208 9.2196 6.6575 0.4495     0.0000   \n",
       "2 0.1341 63.9627 266.5581 1013.5480 7.6623 6.0854 0.5470     0.0000   \n",
       "3 0.4217 65.6833 266.5581 1015.3088 9.5372 5.7522 0.8203     0.0000   \n",
       "4 0.2284 67.5053 266.5581 1015.6050 8.5467 4.4955 0.8328     0.0000   \n",
       "\n",
       "   LC_LowDev  LC_HighDev      PS    relh   Popd  primary  secondary  motorway  \\\n",
       "0     0.0000      8.2791 10.5829 68.6514 0.0000   0.0000     0.0000    0.0000   \n",
       "1     0.0000      6.6575 10.5829 70.3450 0.0000   0.0000     0.0000    0.0000   \n",
       "2     0.0000      6.0854 10.5829 76.1868 0.0000   0.0000     0.0000    0.0000   \n",
       "3     0.0000      5.7522 10.5829 72.9863 0.0000   0.0000     0.0000    0.0000   \n",
       "4     0.0000      4.4955 10.5829 80.3597 0.0000   0.0000     0.0000    0.0000   \n",
       "\n",
       "    pred  Raster.Cell  month  year  \n",
       "0 7.9458          610      4    14  \n",
       "1 8.3105          610      5    14  \n",
       "2 9.9541          610      6    14  \n",
       "3 9.7878          610      7    14  \n",
       "4 8.8360          610      8    14  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2=df_2.drop([2,3,4,5,6,7,8,9,10,11,12,15,16,17,18],axis=1)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raster.Cell</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>AOD</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Elev</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Vsby</th>\n",
       "      <th>WdVl</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>...</th>\n",
       "      <th>LC_HighDev</th>\n",
       "      <th>PS</th>\n",
       "      <th>relh</th>\n",
       "      <th>Popd</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3798</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>27.2144</td>\n",
       "      <td>202.6511</td>\n",
       "      <td>1018.8516</td>\n",
       "      <td>8.4725</td>\n",
       "      <td>8.4067</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4067</td>\n",
       "      <td>13.1464</td>\n",
       "      <td>68.5915</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-87.9144</td>\n",
       "      <td>43.0569</td>\n",
       "      <td>83.3885</td>\n",
       "      <td>8613.3285</td>\n",
       "      <td>1269.4493</td>\n",
       "      <td>14.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3798</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>42.5520</td>\n",
       "      <td>202.6511</td>\n",
       "      <td>1014.2213</td>\n",
       "      <td>8.7911</td>\n",
       "      <td>8.7160</td>\n",
       "      <td>0.2352</td>\n",
       "      <td>...</td>\n",
       "      <td>8.7160</td>\n",
       "      <td>13.1464</td>\n",
       "      <td>67.1438</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-87.9144</td>\n",
       "      <td>43.0569</td>\n",
       "      <td>83.3885</td>\n",
       "      <td>8613.3285</td>\n",
       "      <td>1269.4493</td>\n",
       "      <td>6.8000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3798</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>55.1383</td>\n",
       "      <td>202.6511</td>\n",
       "      <td>1015.4208</td>\n",
       "      <td>9.1797</td>\n",
       "      <td>7.0120</td>\n",
       "      <td>0.3894</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0120</td>\n",
       "      <td>13.1464</td>\n",
       "      <td>68.5747</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-87.9144</td>\n",
       "      <td>43.0569</td>\n",
       "      <td>83.3885</td>\n",
       "      <td>8613.3285</td>\n",
       "      <td>1269.4493</td>\n",
       "      <td>5.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3798</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>0.1658</td>\n",
       "      <td>63.7574</td>\n",
       "      <td>202.6511</td>\n",
       "      <td>1013.5480</td>\n",
       "      <td>7.3425</td>\n",
       "      <td>6.3811</td>\n",
       "      <td>0.4190</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3811</td>\n",
       "      <td>13.1464</td>\n",
       "      <td>74.5546</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-87.9144</td>\n",
       "      <td>43.0569</td>\n",
       "      <td>83.3885</td>\n",
       "      <td>8613.3285</td>\n",
       "      <td>1269.4493</td>\n",
       "      <td>7.5714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3798</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.2997</td>\n",
       "      <td>66.0770</td>\n",
       "      <td>202.6511</td>\n",
       "      <td>1015.3088</td>\n",
       "      <td>9.4635</td>\n",
       "      <td>6.0967</td>\n",
       "      <td>0.4372</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0967</td>\n",
       "      <td>13.1464</td>\n",
       "      <td>69.6442</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>-87.9144</td>\n",
       "      <td>43.0569</td>\n",
       "      <td>83.3885</td>\n",
       "      <td>8613.3285</td>\n",
       "      <td>1269.4493</td>\n",
       "      <td>8.4714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Raster.Cell  month  year    AOD    Temp     Elev      MSLP   Vsby   WdVl  \\\n",
       "0         3798      3    14 0.1026 27.2144 202.6511 1018.8516 8.4725 8.4067   \n",
       "1         3798      4    14 0.0624 42.5520 202.6511 1014.2213 8.7911 8.7160   \n",
       "2         3798      5    14 0.1815 55.1383 202.6511 1015.4208 9.1797 7.0120   \n",
       "3         3798      6    14 0.1658 63.7574 202.6511 1013.5480 7.3425 6.3811   \n",
       "4         3798      7    14 0.2997 66.0770 202.6511 1015.3088 9.4635 6.0967   \n",
       "\n",
       "    NDVI  ...  LC_HighDev      PS    relh   Popd        x       y  primary  \\\n",
       "0 0.1605  ...      8.4067 13.1464 68.5915 0.0028 -87.9144 43.0569  83.3885   \n",
       "1 0.2352  ...      8.7160 13.1464 67.1438 0.0028 -87.9144 43.0569  83.3885   \n",
       "2 0.3894  ...      7.0120 13.1464 68.5747 0.0028 -87.9144 43.0569  83.3885   \n",
       "3 0.4190  ...      6.3811 13.1464 74.5546 0.0028 -87.9144 43.0569  83.3885   \n",
       "4 0.4372  ...      6.0967 13.1464 69.6442 0.0028 -87.9144 43.0569  83.3885   \n",
       "\n",
       "   secondary  motorway    pred  \n",
       "0  8613.3285 1269.4493 14.3000  \n",
       "1  8613.3285 1269.4493  6.8000  \n",
       "2  8613.3285 1269.4493  5.6000  \n",
       "3  8613.3285 1269.4493  7.5714  \n",
       "4  8613.3285 1269.4493  8.4714  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the dataframe from stage one and stage two to get the data for stage three\n",
    "df_3 = df\n",
    "df_3['pred'] = df_3['Sen2.5']\n",
    "df_3=df_3.drop('Sen2.5', axis=1)\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_2.append(df_3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOD</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Elev</th>\n",
       "      <th>MSLP</th>\n",
       "      <th>Vsby</th>\n",
       "      <th>WdVl</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>LC_MedDev</th>\n",
       "      <th>LC_LowDev</th>\n",
       "      <th>LC_HighDev</th>\n",
       "      <th>...</th>\n",
       "      <th>Popd</th>\n",
       "      <th>primary</th>\n",
       "      <th>secondary</th>\n",
       "      <th>motorway</th>\n",
       "      <th>pred</th>\n",
       "      <th>Raster.Cell</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1652</td>\n",
       "      <td>42.3448</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1014.2213</td>\n",
       "      <td>8.9448</td>\n",
       "      <td>8.2791</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.2791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.9458</td>\n",
       "      <td>610</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1203</td>\n",
       "      <td>55.0620</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.4208</td>\n",
       "      <td>9.2196</td>\n",
       "      <td>6.6575</td>\n",
       "      <td>0.4495</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.6575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.3105</td>\n",
       "      <td>610</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1341</td>\n",
       "      <td>63.9627</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1013.5480</td>\n",
       "      <td>7.6623</td>\n",
       "      <td>6.0854</td>\n",
       "      <td>0.5470</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.9541</td>\n",
       "      <td>610</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4217</td>\n",
       "      <td>65.6833</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.3088</td>\n",
       "      <td>9.5372</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.7522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.7878</td>\n",
       "      <td>610</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2284</td>\n",
       "      <td>67.5053</td>\n",
       "      <td>266.5581</td>\n",
       "      <td>1015.6050</td>\n",
       "      <td>8.5467</td>\n",
       "      <td>4.4955</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.4955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.8360</td>\n",
       "      <td>610</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538180</th>\n",
       "      <td>0.1504</td>\n",
       "      <td>71.8913</td>\n",
       "      <td>180.4956</td>\n",
       "      <td>1012.8235</td>\n",
       "      <td>8.9683</td>\n",
       "      <td>5.5281</td>\n",
       "      <td>0.7966</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.5281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.6492</td>\n",
       "      <td>46895</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>-88.1858</td>\n",
       "      <td>41.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538181</th>\n",
       "      <td>0.2035</td>\n",
       "      <td>73.6890</td>\n",
       "      <td>180.4956</td>\n",
       "      <td>1017.0145</td>\n",
       "      <td>9.6198</td>\n",
       "      <td>4.5049</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.5049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.2063</td>\n",
       "      <td>46895</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>-88.1858</td>\n",
       "      <td>41.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538182</th>\n",
       "      <td>0.2873</td>\n",
       "      <td>73.9405</td>\n",
       "      <td>180.4956</td>\n",
       "      <td>1015.0842</td>\n",
       "      <td>9.0310</td>\n",
       "      <td>4.5487</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.5487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.5701</td>\n",
       "      <td>46895</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>-88.1858</td>\n",
       "      <td>41.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538183</th>\n",
       "      <td>0.1025</td>\n",
       "      <td>52.0867</td>\n",
       "      <td>180.4956</td>\n",
       "      <td>1017.4701</td>\n",
       "      <td>9.2085</td>\n",
       "      <td>6.4142</td>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.4142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.2483</td>\n",
       "      <td>46895</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>-88.1858</td>\n",
       "      <td>41.2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538184</th>\n",
       "      <td>0.1418</td>\n",
       "      <td>32.8074</td>\n",
       "      <td>180.4956</td>\n",
       "      <td>1018.7173</td>\n",
       "      <td>8.2566</td>\n",
       "      <td>6.4069</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.4069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.1177</td>\n",
       "      <td>46895</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>-88.1858</td>\n",
       "      <td>41.2243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538185 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AOD    Temp     Elev      MSLP   Vsby   WdVl   NDVI  LC_MedDev  \\\n",
       "0       0.1652 42.3448 266.5581 1014.2213 8.9448 8.2791 0.2914     0.0000   \n",
       "1       0.1203 55.0620 266.5581 1015.4208 9.2196 6.6575 0.4495     0.0000   \n",
       "2       0.1341 63.9627 266.5581 1013.5480 7.6623 6.0854 0.5470     0.0000   \n",
       "3       0.4217 65.6833 266.5581 1015.3088 9.5372 5.7522 0.8203     0.0000   \n",
       "4       0.2284 67.5053 266.5581 1015.6050 8.5467 4.4955 0.8328     0.0000   \n",
       "...        ...     ...      ...       ...    ...    ...    ...        ...   \n",
       "1538180 0.1504 71.8913 180.4956 1012.8235 8.9683 5.5281 0.7966     0.0300   \n",
       "1538181 0.2035 73.6890 180.4956 1017.0145 9.6198 4.5049 0.7862     0.0300   \n",
       "1538182 0.2873 73.9405 180.4956 1015.0842 9.0310 4.5487 0.6050     0.0300   \n",
       "1538183 0.1025 52.0867 180.4956 1017.4701 9.2085 6.4142 0.3524     0.0300   \n",
       "1538184 0.1418 32.8074 180.4956 1018.7173 8.2566 6.4069 0.3047     0.0300   \n",
       "\n",
       "         LC_LowDev  LC_HighDev  ...   Popd  primary  secondary  motorway  \\\n",
       "0           0.0000      8.2791  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "1           0.0000      6.6575  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "2           0.0000      6.0854  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "3           0.0000      5.7522  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "4           0.0000      4.4955  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "...            ...         ...  ...    ...      ...        ...       ...   \n",
       "1538180     0.0000      5.5281  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "1538181     0.0000      4.5049  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "1538182     0.0000      4.5487  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "1538183     0.0000      6.4142  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "1538184     0.0000      6.4069  ... 0.0000   0.0000     0.0000    0.0000   \n",
       "\n",
       "          pred  Raster.Cell  month  year        x       y  \n",
       "0       7.9458          610      4    14      nan     nan  \n",
       "1       8.3105          610      5    14      nan     nan  \n",
       "2       9.9541          610      6    14      nan     nan  \n",
       "3       9.7878          610      7    14      nan     nan  \n",
       "4       8.8360          610      8    14      nan     nan  \n",
       "...        ...          ...    ...   ...      ...     ...  \n",
       "1538180 6.6492        46895      6    18 -88.1858 41.2243  \n",
       "1538181 7.2063        46895      7    18 -88.1858 41.2243  \n",
       "1538182 9.5701        46895      8    18 -88.1858 41.2243  \n",
       "1538183 5.2483        46895     10    18 -88.1858 41.2243  \n",
       "1538184 8.1177        46895     12    18 -88.1858 41.2243  \n",
       "\n",
       "[1538185 rows x 22 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.to_csv('../../Downloads/Third_stage_spatialcv_ipw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.to_csv('../../Downloads/Third_stage_base_ipw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.to_csv('../../Downloads/Third_stage_outlier_ipw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
